{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbee20ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "dev = json.load(open(\"../data/individual_dev_end2end_final.json\"))\n",
    "\n",
    "get_lemma = lambda x:\" \".join([token.lemma_ for token in nlp(x)])\n",
    "\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "relation_trigger = ['before', 'after', 'during', 'while']\n",
    "\n",
    "warmup_qs = ['What will happen in the future?', 'What event has already finished?', \n",
    "             'What event has begun but has not finished?', 'What is happening now?',\n",
    "             'What event has already happened?', 'What event has started?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66262cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1483/1483 [1:18:26<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "zero_shot_results = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "#     prompt = f\"Given the context {context}, {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"}A:\"\n",
    "    \n",
    "    zero_shot_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5289743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 27762.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.3980\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4533\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3684\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0539\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0816\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0021\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0082\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0186\n"
     ]
    }
   ],
   "source": [
    "from eval_func_gpt3 import evaluate\n",
    "evaluate(zero_shot_results, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56a787",
   "metadata": {},
   "source": [
    "# one shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a7c126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85109ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n",
      "{'answers': {'labels': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'context': ['A', 'public', 'security', 'bureau', 'official', 'said', 'the', 'police', 'were', 'unable', 'to', 'comment', 'on', 'the', 'statement', '.', 'But', 'Shanghai', 'police', 'did', 'say', 'that', 'on', 'March', '24', 'they', 'had', 'taken', 'similar', 'action', 'against', 'Bishop', 'Joseph', 'Fan', 'Zhongliang', ',', 'coadjutor', 'of', 'the', 'underground', 'Roman', 'Catholic', 'Church', '.'], 'question': 'What happened prior to the public security bureau official speaking?'}\n",
      "Q: What happened prior to the public security bureau official speaking?, select none or several from {said, were, say, taken} \n",
      "A public security bureau official said the police were unable to comment on the statement . But Shanghai police did say that on March 24 they had taken similar action against Bishop Joseph Fan Zhongliang , coadjutor of the underground Roman Catholic Church .\n",
      "A: were, taken\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "random_key = np.random.choice(list(train.keys()), 1)[0]\n",
    "print(random_key[0])\n",
    "item = train[random_key]\n",
    "print(item)\n",
    "\n",
    "context = \" \".join(item['context'])\n",
    "question = item['question']\n",
    "all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "examplar_prompt_0 = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "print(examplar_prompt_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95723e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/template_1_oneshot_exemplar_0.txt', 'w') as writer:\n",
    "    writer.writelines(examplar_prompt_0)\n",
    "with open('results/template_1_oneshot_0_pred', 'w') as writer:\n",
    "    json.dump(one_shot_results_0, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46185dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1483/1483 [53:13<00:00,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "one_shot_results_0 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            one_shot_results_0[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_prompt_0 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "398460b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 34989.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4018\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4344\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3548\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0297\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0452\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0021\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0041\n"
     ]
    }
   ],
   "source": [
    "evaluate(one_shot_results_0, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7848dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docid_wsj_0791_sentid_7_3N8OEVH1FV4K14LQJ53CXLQVB2SOOE_1\n",
      "{'answers': {'labels': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}, 'context': ['Norwood', 'is', 'controlled', 'by', 'Daniel', 'L.', 'Barnett', 'and', 'Paul', 'A.', 'Reese', ',', 'both', 'officers', 'of', 'Boston-based', 'Oasis', 'Capital', 'Management', 'Inc.', ',', 'a', 'small', 'Boston', 'money', 'management', 'firm', '.', 'Also', 'involved', 'in', 'the', 'group', 'is', 'Robert', 'F.', 'Angelo', ',', 'formerly', 'Phoenix', \"'s\", 'senior', 'vice', 'president', ',', 'field', 'operations', ',', 'who', 'left', 'Phoenix', 'at', 'the', 'beginning', 'of', 'October', '.'], 'question': 'What is happening now?'}\n",
      "Q: What is happening now?, select none or several from {controlled, involved, left} \n",
      "Norwood is controlled by Daniel L. Barnett and Paul A. Reese , both officers of Boston-based Oasis Capital Management Inc. , a small Boston money management firm . Also involved in the group is Robert F. Angelo , formerly Phoenix 's senior vice president , field operations , who left Phoenix at the beginning of October .\n",
      "A: controlled\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "random_key = np.random.choice(list(train.keys()), 1)[0]\n",
    "print(random_key)\n",
    "item = train[random_key]\n",
    "print(item)\n",
    "\n",
    "context = \" \".join(item['context'])\n",
    "question = item['question']\n",
    "all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "examplar_prompt_1 = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "print(examplar_prompt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8de27dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1483/1483 [51:41<00:00,  2.09s/it]\n"
     ]
    }
   ],
   "source": [
    "one_shot_results_1 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            one_shot_results_1[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_prompt_1 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356fe4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/template_1_oneshot_exemplar_1.txt', 'w') as writer:\n",
    "    writer.writelines(examplar_prompt_1)\n",
    "with open('results/template_1_oneshot_1_pred', 'w') as writer:\n",
    "    json.dump(one_shot_results_1, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53693a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 49770.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4020\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4470\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3630\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0384\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0600\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0000\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0082\n"
     ]
    }
   ],
   "source": [
    "evaluate(one_shot_results_1, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c481f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docid_AFP_ENG_20051212.0486_sentid_6_3TYCR1GOTD84EQ65SING5PVWKW6ZLK_2\n",
      "{'answers': {'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]}, 'context': ['About', '59', 'percent', 'of', 'eligible', 'Iraqis', 'cast', 'ballots', 'last', 'January', 'for', 'an', 'interim', 'parliament', ',', 'and', '64', 'percent', 'voted', 'in', 'the', 'October', '15', 'referendum', 'on', 'a', 'new', 'constitution', '.', 'The', 'US', 'envoy', 'said', 'that', 'unlike', 'the', 'runup', 'to', 'January', \"'s\", 'ballot', ',', '@', 'the', 'level', 'of', 'violence', 'has', 'dropped', 'my', 'almost', 'any', 'measure', 'over', 'the', 'past', 'few', 'days', 'and', 'we', 'hope', 'that', 'that', 'trend', 'continues', '.', '@'], 'question': 'What will happen in the future?'}\n",
      "Q: What will happen in the future?, select none or several from {cast, ballots, voted, referendum, said, runup, ballot, violence, dropped, hope, trend, continues} \n",
      "About 59 percent of eligible Iraqis cast ballots last January for an interim parliament , and 64 percent voted in the October 15 referendum on a new constitution . The US envoy said that unlike the runup to January 's ballot , @ the level of violence has dropped my almost any measure over the past few days and we hope that that trend continues . @\n",
      "A: none\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "\n",
    "random_key = np.random.choice(list(train.keys()), 1)[0]\n",
    "print(random_key)\n",
    "item = train[random_key]\n",
    "print(item)\n",
    "\n",
    "context = \" \".join(item['context'])\n",
    "question = item['question']\n",
    "all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "if len(ground ) == 0:\n",
    "    ground = ['none']\n",
    "examplar_prompt_2 = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "print(examplar_prompt_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d83f2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|████████████████████▉                                                                                             | 273/1483 [09:08<37:45,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed due to server shutdown {\n",
      "  \"error\": {\n",
      "    \"message\": \"Request failed due to server shutdown\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'Request failed due to server shutdown', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Sat, 17 Jun 2023 08:21:54 GMT', 'Content-Type': 'application/json', 'Content-Length': '141', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'text-davinci-003', 'openai-organization': 'user-7geflohwmbcawqczzwe5bb3a', 'openai-processing-ms': '1936', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249744', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '61ms', 'x-request-id': '241b7ae34174c03fb04031604db51a7f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7d89e1ad0edd14f4-LAX', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████████████████████                                                                                         | 326/1483 [11:04<38:07,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server had an error while processing your request. Sorry about that!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1483/1483 [50:48<00:00,  2.06s/it]\n"
     ]
    }
   ],
   "source": [
    "one_shot_results_2 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            one_shot_results_2[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_prompt_2 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7468381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 37852.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.3988\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4678\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3740\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0937\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.1308\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0062\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0124\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0309\n"
     ]
    }
   ],
   "source": [
    "evaluate(one_shot_results_2, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5217f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/template_1_oneshot_exemplar_2.txt', 'w') as writer:\n",
    "    writer.writelines(examplar_prompt_2)\n",
    "with open('results/template_1_oneshot_2_pred', 'w') as writer:\n",
    "    json.dump(one_shot_results_2, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c228f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# three-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "random_keys = np.random.choice(list(train.keys()), 3)\n",
    "print(random_keys)\n",
    "items = [train[k] for k in random_keys]\n",
    "print(items)\n",
    "\n",
    "\n",
    "examplar_list = []\n",
    "for item in items:\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    if len(ground) == 0:\n",
    "        ground = ['none']\n",
    "    tmp_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "    examplar_list.append(tmp_prompt)\n",
    "examplar_threeshot_0 = \"\\n\\n\".join(examplar_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_shot_results_0 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            three_shot_results_0[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_threeshot_0 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3e3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc4a02e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['docid_wsj_0791_sentid_7_3N8OEVH1FV4K14LQJ53CXLQVB2SOOE_1'\n",
      " 'docid_AFP_ENG_19970417.0024_sentid_1_35K3O9HUAC2K335DAK65P2PU4IFFEA_5'\n",
      " 'docid_AFP_ENG_20051215.0093_sentid_16_3J4Q2Z4UTZSBBSHD90B5N708JY9WQ2_0']\n",
      "[{'answers': {'labels': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]}, 'context': ['Norwood', 'is', 'controlled', 'by', 'Daniel', 'L.', 'Barnett', 'and', 'Paul', 'A.', 'Reese', ',', 'both', 'officers', 'of', 'Boston-based', 'Oasis', 'Capital', 'Management', 'Inc.', ',', 'a', 'small', 'Boston', 'money', 'management', 'firm', '.', 'Also', 'involved', 'in', 'the', 'group', 'is', 'Robert', 'F.', 'Angelo', ',', 'formerly', 'Phoenix', \"'s\", 'senior', 'vice', 'president', ',', 'field', 'operations', ',', 'who', 'left', 'Phoenix', 'at', 'the', 'beginning', 'of', 'October', '.'], 'question': 'What is happening now?'}, {'answers': {'labels': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}, 'context': ['Danai', ',', '61', ',', 'who', 'died', 'Monday', ',', 'was', 'appointed', 'in', 'early', '1995', 'as', 'the', 'first', 'Thai', 'ambassdor', 'to', 'the', 'WTO', ',', 'where', 'he', 'chaired', 'the', 'agriculture', 'committee', 'before', 'retiring', 'at', 'age', '60', '.', 'Before', 'working', 'at', 'the', 'WTO', ',', 'he', 'held', 'posts', 'as', 'deputy', 'permanent', 'secretary', 'of', 'the', 'commerce', 'ministry', 'and', 'director-general', 'of', 'the', 'foreign', 'ministry', \"'s\", 'economic', 'department', '.'], 'question': 'What happened before Danai held posts as deputy permanent secretary and director-general?'}, {'answers': {'labels': [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'types': [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]}, 'context': ['Otherwise', ',', 'when', 'the', 'mood', 'turned', 'sour', 'in', 'Myanmar', 'the', 'generals', 'would', 'simply', 'retrace', 'their', 'steps', 'and', 'haul', 'all', 'their', 'opponents', 'back', 'to', 'jail', '.', '@', 'Burma', '(', 'Myanmar', ')', 'has', 'a', 'habit', 'of', 'recycling', 'political', 'prisoners', '.'], 'question': 'What event has already finished?'}]\n"
     ]
    }
   ],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "random_keys = np.random.choice(list(train.keys()), 3)\n",
    "print(random_keys)\n",
    "items = [train[k] for k in random_keys]\n",
    "print(items)\n",
    "\n",
    "\n",
    "examplar_list = []\n",
    "for item in items:\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    if len(ground) == 0:\n",
    "        ground = ['none']\n",
    "    tmp_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "    examplar_list.append(tmp_prompt)\n",
    "examplar_threeshot_1 = \"\\n\\n\".join(examplar_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4428312",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_shot_results_1 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            three_shot_results_1[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_threeshot_1 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6144f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155cce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))\n",
    "import numpy as np\n",
    "np.random.seed(3)\n",
    "\n",
    "random_keys = np.random.choice(list(train.keys()), 3)\n",
    "print(random_keys)\n",
    "items = [train[k] for k in random_keys]\n",
    "print(items)\n",
    "\n",
    "\n",
    "examplar_list = []\n",
    "for item in items:\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    if len(ground) == 0:\n",
    "        ground = ['none']\n",
    "    tmp_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "    examplar_list.append(tmp_prompt)\n",
    "examplar_threeshot_2 = \"\\n\\n\".join(examplar_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de62ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_shot_results_2 = {}\n",
    "for key, item in tqdm(dev.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            three_shot_results_2[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=examplar_threeshot_2 + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
