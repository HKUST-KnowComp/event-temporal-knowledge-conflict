{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56d0e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "dev = json.load(open(\"../data/individual_dev_end2end_final.json\"))\n",
    "\n",
    "get_lemma = lambda x:\" \".join([token.lemma_ for token in nlp(x)])\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "relation_trigger = ['before', 'after', 'during', 'while']\n",
    "\n",
    "warmup_qs = ['What will happen in the future?', 'What event has already finished?', \n",
    "             'What event has begun but has not finished?', 'What is happening now?',\n",
    "             'What event has already happened?', 'What event has started?', \n",
    "            ]\n",
    "\n",
    "\n",
    "def parse_question(q, event_lemmas):\n",
    "    \"\"\"\n",
    "        input: q: question, events: the set of lemmatized events.\n",
    "        output: \n",
    "            q_events: events in the question\n",
    "            modality: whether there's \"might/will/can/may/...\"\n",
    "            base_temp_rel: basic temporal relations, [\"before\", \"after\", \"during\", \"while\"]\n",
    "    \"\"\"\n",
    "    # acquire the events in the question stem\n",
    "    q_events = [e for e in [token.lemma_ for token in nlp(q)] if e in event_lemmas]\n",
    "    \n",
    "    second_prefix = q.split()[1]\n",
    "\n",
    "    rel_trigger = [t for t in q.split() if t in relation_trigger]\n",
    "\n",
    "    if len(rel_trigger) > 0:\n",
    "        base_temp_rel = rel_trigger[0]\n",
    "    else:\n",
    "        base_temp_rel = \"\"\n",
    "        \n",
    "    return q_events, second_prefix, base_temp_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f085040",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_warmup = {\n",
    "    \n",
    "    'What will happen in the future?':\"will happen in the future\",\n",
    "    'What event has already finished?':\"has already finished\", \n",
    "    'What event has begun but has not finished?':\"has begun but has not finished\", \n",
    "    'What is happening now?':\"is happening now\",\n",
    "    'What event has already happened?':\"has already happened\", \n",
    "    'What event has started?':\"has started\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_prompt = f\"Write a story where '{', '.join(exmp_ans)}' {prompt_warmup[exmp_question]} within 100 words:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfa6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "exmp_context = \"Pope John Paul II on Friday appointed two Chinese scientists -- one from Taiwan , the other from the mainland -- to the Pontifical Academy of Sciences . The two are Chin Ningyang , 74 , from Hefei in China , the 1957 Nobel Physics Prize winner and son of a mathematics professor at Beijing university .\"\n",
    "exmp_all_events = [\"appointed\", \"are\", \"winner\"]\n",
    "exmp_ans = [\"appointed\", \"winner\"]\n",
    "exmp_question = \"What event has already finished?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786707b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_prompt = f\"Write a story where '{', '.join(exmp_ans)}' {prompt_warmup[exmp_question]} within 100 words:\\n{exmp_context}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "810d49c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Write a story where 'appointed, winner' has already finished within 100 words:\\nPope John Paul II on Friday appointed two Chinese scientists -- one from Taiwan , the other from the mainland -- to the Pontifical Academy of Sciences . The two are Chin Ningyang , 74 , from Hefei in China , the 1957 Nobel Physics Prize winner and son of a mathematics professor at Beijing university .\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38f8b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_warmup_tense = json.load(open(\"../data/dataset_bias_new/individual_dev_warmup_tense_bias.json\"))\n",
    "\n",
    "# with open(\"data/warmup_tense_examplar_gpt3_oneshot_pred.json\", 'w') as outfile:\n",
    "#     json.dump(oneshot_gen_results, outfile)\n",
    "    \n",
    "oneshot_gen_results = json.load(open(\"data/warmup_tense_examplar_gpt3_oneshot_pred.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c400c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba2234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8016b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [07:59<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "generated_examplars_cf = {}\n",
    "generated_examplars_answers_cf = {}\n",
    "examplar_prompts_cf = {}\n",
    "\n",
    "for key, item in tqdm(dev_warmup_tense.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "\n",
    "    event_lemmas = [get_lemma(e) for e in all_events]\n",
    "    \n",
    "#     if not question in warmup_qs:\n",
    "#     question_events, _, rel = parse_question(question, event_lemmas)\n",
    "    gpt3_answers = [w.lower().strip().replace(\".\", \"\") for w in oneshot_gen_results[key].split(\",\")]\n",
    "    selected_ans = list(set(all_events) - set(gpt3_answers))\n",
    "#         print(len(selected_ans), len(gpt3_answers), len(all_events))\n",
    "#         print(selected_ans, gpt3_answers, all_events)\n",
    "    prompt = f\"Write a story where '{', '.join(selected_ans)}' {prompt_warmup[question]} within 100 words:\"\n",
    "#     else:\n",
    "#         assert False\n",
    "    \n",
    "    generated_examplars_answers_cf[key] = selected_ans\n",
    "\n",
    "    generated_examplars_cf[key] = openai.Completion.create(\n",
    "                                          model=\"text-davinci-003\",\n",
    "                                          prompt=prompt,\n",
    "                                          max_tokens=100,\n",
    "                                          temperature=0\n",
    "                                )[\"choices\"][0][\"text\"].strip()\n",
    "    time.sleep(2)\n",
    "    # \n",
    "#     question = f\"What happened {rel} {question_events[0]}?\"\n",
    "    context = generated_examplars_cf[key]\n",
    "    gen_answers = generated_examplars_answers_cf[key]\n",
    "    ex_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA: \" + ', '.join(gen_answers)\n",
    "\n",
    "    examplar_prompts_cf[key] = ex_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b846f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid_AFP_ENG_20061201.0595_sentid_2_6': 'Q: What will happen in the future?, select none or several from {meet, requires, delivered, said, designed, compete, proved} \\nThe future requires a new kind of delivery system. One that can meet the needs of a rapidly changing world. After years of research and development, the new system is finally ready. It is capable of delivering anything, anywhere, anytime. It is faster, more efficient, and more reliable than anything that has come before. The world is ready to meet the new system and see what it can do. With its help, the future looks brighter than ever.\\nA: requires, delivered, meet'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplar_prompts_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad398ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [03:43<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_gen_cf_results = {}\n",
    "for key, item in tqdm(dev_warmup_tense.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    examplar = examplar_prompts_cf[key]\n",
    "    \n",
    "    oneshot_gen_cf_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=examplar + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9edb55b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'docid_AFP_ENG_20061201.0595_sentid_2_6': 'meet, requires, delivered, said, designed, compete, proved'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneshot_gen_cf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1effe179",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_func_gpt3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbaa40d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:00, 36343.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 71 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4232\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4754\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4010\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0141\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0282\n",
      "Eval on 70 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0143\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0286\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.1571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(oneshot_gen_cf_results, dev_warmup_tense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881a2ca",
   "metadata": {},
   "source": [
    "# random sample examplar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9873a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1771e765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['docid_AFP_ENG_20061220.0595_sentid_4_3VP0C6EFSHLMWY4FQPRK84HQEUIM6U_0'],\n",
       "      dtype='<U76')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(list(train.keys()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edaddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train['docid_AFP_ENG_20061220.0595_sentid_4_3VP0C6EFSHLMWY4FQPRK84HQEUIM6U_0']\n",
    "context = \" \".join(item['context'])\n",
    "question = item['question']\n",
    "all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "examplar_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9ad1c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 71/71 [03:38<00:00,  3.07s/it]\n"
     ]
    }
   ],
   "source": [
    "icl_cf_results = {}\n",
    "for key, item in tqdm(dev_warmup_tense.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    examplar = examplar_prompts_cf[key]\n",
    "    \n",
    "    icl_cf_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=examplar_prompt + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fae1d863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:00, 37210.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 71 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4654\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5260\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4515\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0563\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0845\n",
      "Eval on 70 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0571\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0857\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(icl_cf_results, dev_warmup_tense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6581d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_warmup_ans = json.load(open(\"../data/dataset_bias_new/individual_dev_warmup_answer_bias.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a22bde17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [03:29<00:00,  3.18s/it]\n"
     ]
    }
   ],
   "source": [
    "icl_cf_results_ans = {}\n",
    "for key, item in tqdm(dev_warmup_ans.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    examplar = examplar_prompts_cf[key]\n",
    "    \n",
    "    icl_cf_results_ans[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=examplar_prompt + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b027f23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:00, 61122.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 66 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4849\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5559\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4736\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0606\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0909\n",
      "Eval on 65 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0615\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0923\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(icl_cf_results_ans, dev_warmup_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b57b8e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_erp = json.load(open(\"../data/dataset_bias_new/individual_dev_erp_bias.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a8b5b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 88/88 [04:52<00:00,  3.33s/it]\n",
      "88it [00:00, 60045.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 88 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5288\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5802\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5054\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0227\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0341\n",
      "Eval on 64 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0156\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0312\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "icl_cf_results_erp = {}\n",
    "for key, item in tqdm(dev_erp.items()):\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    icl_cf_results_erp[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=examplar_prompt + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)\n",
    "evaluate(icl_cf_results_erp, dev_erp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d12f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
