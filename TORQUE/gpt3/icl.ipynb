{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1521a9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "dev = json.load(open(\"../data/individual_dev_end2end_final.json\"))\n",
    "\n",
    "get_lemma = lambda x:\" \".join([token.lemma_ for token in nlp(x)])\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "relation_trigger = ['before', 'after', 'during', 'while']\n",
    "\n",
    "warmup_qs = ['What will happen in the future?', 'What event has already finished?', \n",
    "             'What event has begun but has not finished?', 'What is happening now?',\n",
    "             'What event has already happened?', 'What event has started?', \n",
    "            ]\n",
    "\n",
    "def parse_question(q, event_lemmas):\n",
    "    \"\"\"\n",
    "        input: q: question, events: the set of lemmatized events.\n",
    "        output: \n",
    "            q_events: events in the question\n",
    "            modality: whether there's \"might/will/can/may/...\"\n",
    "            base_temp_rel: basic temporal relations, [\"before\", \"after\", \"during\", \"while\"]\n",
    "    \"\"\"\n",
    "    # acquire the events in the question stem\n",
    "    q_events = [e for e in [token.lemma_ for token in nlp(q)] if e in event_lemmas]\n",
    "    \n",
    "    second_prefix = q.split()[1]\n",
    "\n",
    "    rel_trigger = [t for t in q.split() if t in relation_trigger]\n",
    "\n",
    "    if len(rel_trigger) > 0:\n",
    "        base_temp_rel = rel_trigger[0]\n",
    "    else:\n",
    "        base_temp_rel = \"\"\n",
    "        \n",
    "    return q_events, second_prefix, base_temp_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b53fcf",
   "metadata": {},
   "source": [
    "# ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0d0668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b551a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_end2end_final.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ef99ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_keys = ['docid_AFP_ENG_19970418.0574_sentid_0_32VNZTT0A8TZERDTC9UMX5RMOW14RH_0',\n",
    "            'docid_XIN_ENG_20061130.0405_sentid_0_31N2WW6R9SFHT5PGL0P96BLX90ZF33_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f07726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What event has already finished?, select none or several from {appointed, are, winner} \n",
      "Pope John Paul II on Friday appointed two Chinese scientists -- one from Taiwan , the other from the mainland -- to the Pontifical Academy of Sciences . The two are Chin Ningyang , 74 , from Hefei in China , the 1957 Nobel Physics Prize winner and son of a mathematics professor at Beijing university .\n",
      "A: appointed, winner\n",
      "\n",
      "Q: What will happen after Mora is named Attorney General?, select none or several from {named, assist, start, named} \n",
      "Mexico 's president-elect Felipe Calderon , of the ruling National Action Party ( PAN ) , named on Thursday the last four cabinet ministers who will assist him in his six-year term to start on Dec. 1 . Calderon named Eduardo Medina Mora as Attorney General , Genaro Garcia Luna as Public Security Minister , Guillermo Galvan Galvan as Minister of National Defense and Mariano Francisco Sainez Mendoza as Navy Minister .\n",
      "A: assist, start\n"
     ]
    }
   ],
   "source": [
    "# construct examplar\n",
    "exm_prompts = []\n",
    "for key in icl_keys:\n",
    "    item = train[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + f\"\\nA: {', '.join(ground)}\"\n",
    "    exm_prompts.append(prompt)\n",
    "print(\"\\n\\n\".join(exm_prompts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a94a417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: What event has already finished?, select none or several from {appointed, are, winner} \\nPope John Paul II on Friday appointed two Chinese scientists -- one from Taiwan , the other from the mainland -- to the Pontifical Academy of Sciences . The two are Chin Ningyang , 74 , from Hefei in China , the 1957 Nobel Physics Prize winner and son of a mathematics professor at Beijing university .\\nA: appointed, winner'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exm_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d871a3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Q: What will happen after Mora is named Attorney General?, select none or several from {named, assist, start, named} \\nMexico 's president-elect Felipe Calderon , of the ruling National Action Party ( PAN ) , named on Thursday the last four cabinet ministers who will assist him in his six-year term to start on Dec. 1 . Calderon named Eduardo Medina Mora as Attorney General , Genaro Garcia Luna as Public Security Minister , Guillermo Galvan Galvan as Minister of National Defense and Mariano Francisco Sainez Mendoza as Navy Minister .\\nA: assist, start\""
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exm_prompts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "37267a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                                                   | 5/1483 [00:11<57:51,  2.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [170], line 18\u001b[0m\n\u001b[1;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, select none or several from \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(all_events) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m} \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m icl_results_0[key] \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     12\u001b[0m           model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m           prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(exm_prompts[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prompt,\n\u001b[1;32m     14\u001b[0m           max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     15\u001b[0m           temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     16\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "icl_results_0 = {}\n",
    "for key in tqdm(dev):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            icl_results_0[key] = openai.Completion.create(\n",
    "                      model=\"text-davinci-003\",\n",
    "                      prompt=\"\\n\\n\".join(exm_prompts[0]) + \"\\n\\n\" + prompt,\n",
    "                      max_tokens=256,\n",
    "                      temperature=0\n",
    "            )[\"choices\"][0][\"text\"].strip()\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    \n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e005e6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5db6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5017826",
   "metadata": {},
   "source": [
    "# test gpt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f99de134",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "sampled_keys = np.random.choice(list(dev.keys()), 200, replace=False)\n",
    "the_rest_keys = list(set(dev.keys()) - set(sampled_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff288a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "744e1be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [09:26<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "icl_results = {}\n",
    "for key in tqdm(sampled_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    \n",
    "    icl_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=\"\\n\\n\".join(exm_prompts) + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a537797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1283/1283 [26:50<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(the_rest_keys):\n",
    "    if key in icl_results:\n",
    "        continue\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    \n",
    "    icl_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=\"\\n\\n\".join(exm_prompts) + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52ad7a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cebf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_func_gpt3 import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "728d38cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4224\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4562\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3760\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0526\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0762\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0021\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0021\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0165\n"
     ]
    }
   ],
   "source": [
    "evaluate(icl_results, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6c3898ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erp\n",
      "Total 88 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5674\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.6340\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5426\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0455\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0795\n",
      "Eval on 64 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0312\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0625\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.3125\n",
      "\n",
      "\n",
      "\n",
      "erp_warm\n",
      "Total 66 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5240\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5858\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5199\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0758\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.1515\n",
      "Eval on 65 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0769\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.1538\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.3077\n",
      "\n",
      "\n",
      "\n",
      "narrative\n",
      "Total 140 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4716\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5391\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4657\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0286\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0357\n",
      "Eval on 94 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0319\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0426\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2234\n",
      "\n",
      "\n",
      "\n",
      "tense\n",
      "Total 243 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4994\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5766\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4912\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0453\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0741\n",
      "Eval on 157 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0510\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0637\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2548\n",
      "\n",
      "\n",
      "\n",
      "tense_warm\n",
      "Total 71 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5132\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5643\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5073\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0704\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.1408\n",
      "Eval on 70 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0714\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.1429\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2857\n",
      "\n",
      "\n",
      "\n",
      "dependency\n",
      "Total 68 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5060\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5752\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4916\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0294\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0294\n",
      "Eval on 58 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0345\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0345\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2414\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cls in existing_results:\n",
    "    print(cls)\n",
    "    evaluate(dict([(key, icl_results[key]) for key in existing_results[cls]]), \n",
    "             dict([(key, dev[key]) for key in existing_results[cls]]))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efd76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24978b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "896a63aa",
   "metadata": {},
   "source": [
    "# zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f2594ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [09:34<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "zs_results = {}\n",
    "for key in tqdm(sampled_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    \n",
    "    zs_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54081408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▎                                                                                                             | 37/1283 [01:50<1:02:04,  2.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 17\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, select none or several from \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(all_events) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m} \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mA:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m zs_results[key] \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     11\u001b[0m           model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m           prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     13\u001b[0m           max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     14\u001b[0m           temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m )[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 17\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in tqdm(the_rest_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    \n",
    "    zs_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef757b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "add6da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 27368.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 200 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4078\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4359\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3459\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0450\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0850\n",
      "Eval on 161 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0373\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0621\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(zs_results, dict([(k, dev[k]) for k in sampled_keys]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8085428b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nonetheless', ',', 'concern', 'about', 'the', 'chip', 'may',\n",
       "       'have', 'been', 'responsible', 'for', 'a', 'decline', 'of', '87.5',\n",
       "       'cents', 'in', 'Intel', \"'s\", 'stock', 'to', '$', '32', 'a',\n",
       "       'share', 'yesterday', 'in', 'over-the-counter', 'trading', ',',\n",
       "       'on', 'volume', 'of', '3,609,800', 'shares', ',', 'and', 'partly',\n",
       "       'responsible', 'for', 'a', 'drop', 'in', 'Compaq', \"'s\", 'stock',\n",
       "       'in', 'New', 'York', 'Stock', 'Exchange', 'composite', 'trading',\n",
       "       'on', 'Wednesday', '.', 'Yesterday', ',', 'Compaq', 'plunged',\n",
       "       'further', ',', 'closing', 'at', '$', '100', 'a', 'share', ',',\n",
       "       'off', '$', '8.625', 'a', 'share', ',', 'on', 'volume', 'of',\n",
       "       '2,633,700', 'shares', '.'], dtype='<U16')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dev[key]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d2c91abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_to_text(context, labels):\n",
    "    return \", \".join(pd.Series(context)[pd.Series(labels, dtype=bool)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921c2d8",
   "metadata": {},
   "source": [
    "# previous results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7ae170a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs_pred_prev = json.load(open(\"gpt3_pred_dev.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1cbd2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 37519.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.3987\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4548\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3696\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0553\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0836\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0021\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0082\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0165\n"
     ]
    }
   ],
   "source": [
    "evaluate(dict([(key, convert_to_text(dev[key]['context'], val)) for key, val in zs_pred_prev.items()]), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14b65ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "icl_pred_prev = json.load(open(\"./gpt3_fewshot_pred_dev.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ca46488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_icl_pred_prev = json.load(open(\"./gpt3_oneshot_pred_dev.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93c4cfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 64296.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4180\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4604\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3824\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0432\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0593\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0041\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0041\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0144\n"
     ]
    }
   ],
   "source": [
    "evaluate(dict([(key, convert_to_text(dev[key]['context'], val)) for key, val in icl_pred_prev.items()]), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "329bf828",
   "metadata": {},
   "outputs": [],
   "source": [
    "biased_dev = {\n",
    "    \"erp\":json.load(open(\"../data/dataset_bias_new/individual_dev_erp_bias.json\")),\n",
    "    \"erp_warm\":json.load(open(\"../data/dataset_bias_new/individual_dev_warmup_answer_bias.json\")),\n",
    "    \"narrative\":json.load(open(\"../data/dataset_bias_new/individual_dev_narrative_bias.json\")),\n",
    "    \"tense\":json.load(open(\"../data/dataset_bias_new/individual_dev_tense_relation_bias.json\")),\n",
    "    \"tense_warm\":json.load(open(\"../data/dataset_bias_new/individual_dev_warmup_tense_bias.json\")),\n",
    "    \"dependency\":json.load(open(\"../data/dataset_bias_new/individual_dev_dependency_bias.json\")),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09e3ffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erp\n",
      "erp_warm\n",
      "narrative\n",
      "tense\n",
      "tense_warm\n",
      "dependency\n"
     ]
    }
   ],
   "source": [
    "all_existing_keys = set([])\n",
    "for c, dev_subset in biased_dev.items():\n",
    "    print(c)\n",
    "    all_existing_keys = all_existing_keys | set(dev_subset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e6dcdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_keys = set(dev.keys()) - set(all_existing_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "59c2eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4053\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4430\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3642\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0290\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0472\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0000\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0062\n"
     ]
    }
   ],
   "source": [
    "evaluate(dict([(key, convert_to_text(dev[key]['context'], val)) for key, val in oneshot_icl_pred_prev.items()]), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "82150ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "erp\n",
      "Total 88 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5709\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.6117\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5452\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0455\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0795\n",
      "Eval on 64 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0469\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0469\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2031\n",
      "\n",
      "\n",
      "\n",
      "erp_warm\n",
      "Total 66 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5089\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5983\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.5078\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0606\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.1212\n",
      "Eval on 65 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0615\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.1231\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.3077\n",
      "\n",
      "\n",
      "\n",
      "narrative\n",
      "Total 140 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4718\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5313\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4540\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0071\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0071\n",
      "Eval on 94 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0000\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.1915\n",
      "\n",
      "\n",
      "\n",
      "tense\n",
      "Total 243 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4938\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5568\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4822\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0247\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0453\n",
      "Eval on 157 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0318\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0382\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2038\n",
      "\n",
      "\n",
      "\n",
      "tense_warm\n",
      "Total 71 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4917\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5715\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4916\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0563\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.1127\n",
      "Eval on 70 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0571\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.1143\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2857\n",
      "\n",
      "\n",
      "\n",
      "dependency\n",
      "Total 68 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.5075\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5820\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4944\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0294\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0294\n",
      "Eval on 58 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0345\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0345\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2414\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cls in existing_results:\n",
    "    print(cls)\n",
    "    evaluate(dict([(key, convert_to_text(dev[key]['context'], oneshot_icl_pred_prev[key])) for key in existing_results[cls]]), \n",
    "             dict([(key, dev[key]) for key in existing_results[cls]]))\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ccd27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07879274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83ccec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21dfa00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1040/1040 [1:44:03<00:00,  6.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# not warm up questions!!!!\n",
    "np.random.seed(0)\n",
    "generated_examplars_cf = {}\n",
    "generated_examplars_answers_cf = {}\n",
    "examplar_prompts_cf = {}\n",
    "\n",
    "for key in tqdm(other_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "\n",
    "    event_lemmas = [get_lemma(e) for e in all_events]\n",
    "    \n",
    "    if not question in warmup_qs:\n",
    "        question_events, _, rel = parse_question(question, event_lemmas)\n",
    "        gpt3_answers = [w.lower().strip().replace(\".\", \"\") for w in icl_results[key].split(\",\")]\n",
    "        selected_ans = list(set(all_events) - set(gpt3_answers))\n",
    "#         print(len(selected_ans), len(gpt3_answers), len(all_events))\n",
    "#         print(selected_ans, gpt3_answers, all_events)\n",
    "        if len(question_events) == 0:\n",
    "            prompt = f\"Write a story where {question}, {', '.join(selected_ans)} within 100 words\"\n",
    "        else:\n",
    "            prompt = f\"Write a story where '{', '.join(selected_ans)}' happened {rel} '{question_events[0]}' within 100 words:\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    generated_examplars_answers_cf[key] = selected_ans\n",
    "\n",
    "    generated_examplars_cf[key] = openai.Completion.create(\n",
    "                                          model=\"text-davinci-003\",\n",
    "                                          prompt=prompt,\n",
    "                                          max_tokens=100,\n",
    "                                          temperature=0\n",
    "                                )[\"choices\"][0][\"text\"].strip()\n",
    "    time.sleep(1.5)\n",
    "    # \n",
    "#     question = f\"What happened {rel} {question_events[0]}?\"\n",
    "    context = generated_examplars_cf[key]\n",
    "    gen_answers = generated_examplars_answers_cf[key]\n",
    "    ex_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA: \" + ', '.join(gen_answers)\n",
    "\n",
    "    examplar_prompts_cf[key] = ex_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "da0e9a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1040/1040 [10:38<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "question_generator = {\n",
    "    'What will happen in the future?': 'will happen in the future', \n",
    "    'What event has already finished?': 'have happened', \n",
    "    'What event has begun but has not finished?': 'have begun but have not finished', \n",
    "    'What is happening now?': 'is happening now',\n",
    "    'What event has already happened?': 'have happened', \n",
    "    'What event has started?':'have started happening', \n",
    "                     }\n",
    "\n",
    "for key in tqdm(other_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c.lower() for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "\n",
    "    event_lemmas = [get_lemma(e) for e in all_events]\n",
    "    \n",
    "    if question in warmup_qs:\n",
    "#     question_events, _, rel = parse_question(question, event_lemmas)\n",
    "        gpt3_answers = [w.lower().strip().replace(\".\", \"\") for w in icl_results[key].split(\",\")]\n",
    "        selected_ans = list(set(all_events) - set(gpt3_answers))\n",
    "    #         print(len(selected_ans), len(gpt3_answers), len(all_events))\n",
    "    #         print(selected_ans, gpt3_answers, all_events)\n",
    "        prompt = f\"Write a story where '{', '.join(selected_ans)}' {question_generator[question]} within 100 words:\"\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    generated_examplars_answers_cf[key] = selected_ans\n",
    "\n",
    "    generated_examplars_cf[key] = openai.Completion.create(\n",
    "                                          model=\"text-davinci-003\",\n",
    "                                          prompt=prompt,\n",
    "                                          max_tokens=100,\n",
    "                                          temperature=0\n",
    "                                )[\"choices\"][0][\"text\"].strip()\n",
    "    time.sleep(2)\n",
    "\n",
    "    context = generated_examplars_cf[key]\n",
    "    gen_answers = generated_examplars_answers_cf[key]\n",
    "    ex_prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA: \" + ', '.join(gen_answers)\n",
    "\n",
    "    examplar_prompts_cf[key] = ex_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2824edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zs_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e58f229d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['killed']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0bf32b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "399252a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1040/1040 [57:45<00:00,  3.33s/it]\n"
     ]
    }
   ],
   "source": [
    "cf_gen_cf_results = {}\n",
    "for key in tqdm(other_keys):\n",
    "    item = dev[key]\n",
    "    context = \" \".join(item['context'])\n",
    "    question = item['question']\n",
    "    all_events = [c for c, t in zip(item['context'], item[\"answers\"][\"types\"]) if t]\n",
    "    ground = [c for c, t in zip(item['context'], item[\"answers\"][\"labels\"]) if t]\n",
    "    prompt = f\"Q: {question}\" + \", select none or several from {\" + ', '.join(all_events) + \"} \\n\" + context + \"\\nA:\"\n",
    "    \n",
    "    examplar = examplar_prompts_cf[key]\n",
    "    \n",
    "    cf_gen_cf_results[key] = openai.Completion.create(\n",
    "              model=\"text-davinci-003\",\n",
    "              prompt=examplar + \"\\n\\n\" + prompt,\n",
    "              max_tokens=256,\n",
    "              temperature=0\n",
    "    )[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3fb9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b8ec88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_results = {\n",
    "    \"erp\":json.load(open(\"data/erp_examplar_cf_gpt3_oneshot_pred.json\")),\n",
    "    \"erp_warm\":json.load(open(\"data/warmup_ans_examplar_cf_gpt3_oneshot_pred.json\")),\n",
    "    \"narrative\":json.load(open(\"data/narrative_examplar_cf_gpt3_oneshot_pred.json\")),\n",
    "    \"tense\":json.load(open(\"data/tense_examplar_cf_gpt3_oneshot_pred.json\")),\n",
    "    \"tense_warm\":json.load(open(\"data/warmup_tense_examplar_gpt3_oneshot_pred.json\")),\n",
    "    \"dependency\":json.load(open(\"data/dep_examplar_gpt3_oneshot_pred.json\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "23ecc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_results['erp']\n",
    "\n",
    "all_pred = {}\n",
    "for key, val in existing_results.items():\n",
    "    all_pred = {**all_pred, **val}\n",
    "all_pred = {**all_pred, **cf_gen_cf_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3b1c7493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1483it [00:00, 42532.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.0731\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.2834\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.1980\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.1693\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.2441\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0082\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0206\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0206\n"
     ]
    }
   ],
   "source": [
    "evaluate(all_pred, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b1520427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1040it [00:00, 36584.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1040 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.3633\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4032\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3231\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0365\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0606\n",
      "Eval on 450 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0044\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(cf_gen_cf_results, dict([(key, dev[key]) for key in cf_gen_cf_results]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fd935ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_pred = {}\n",
    "for key, val in existing_results.items():\n",
    "    bias_pred = {**bias_pred, **val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0aef2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "443it [00:00, 44903.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 443 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4796\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.5477\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.4706\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0181\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0316\n",
      "Eval on 291 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0241\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0412\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.2131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(bias_pred, dict([(key, dev[key]) for key in bias_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7cfe51bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dev.keys()) - set({**bias_pred, **cf_gen_cf_results}.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dfa0bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dev.keys()), len({**bias_pred, **cf_gen_cf_results})\n",
    "tmp_dev = dict([(key, dev[key]) for key in {**bias_pred, **cf_gen_cf_results}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "749415ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([dev[key] == tmp_dev[key] for key in dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "12b68fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4032\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4463\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3671\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0310\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0519\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0021\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0186\n"
     ]
    }
   ],
   "source": [
    "evaluate({**bias_pred, **cf_gen_cf_results}, dict([(key, dev[key]) for key in {**bias_pred, **cf_gen_cf_results}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b0745186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1483 questions\n",
      "Eval on the current eval positive class Micro F1 (Agg) is: 0.4032\n",
      "Eval on the current eval positive class Macro F1 (Relaxed) is: 0.4463\n",
      "Eval on the current eval positive class Macro F1 (Agg) is: 0.3671\n",
      "Eval on the current eval exact match (Agg) ratio is: 0.0310\n",
      "Eval on the current eval exact match ratio (Relaxed) is: 0.0519\n",
      "Eval on 485 Clusters\n",
      "Eval on the current eval clustered EM (Agg) is: 0.0000\n",
      "Eval on the current eval clustered EM (Relaxed) is: 0.0021\n",
      "Eval on the current eval clusrered F1 (max>=0.8) is: 0.0186\n"
     ]
    }
   ],
   "source": [
    "evaluate({**bias_pred, **cf_gen_cf_results}, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc92d35",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "61dc9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_dict, data_dict):\n",
    "    \n",
    "\n",
    "    def parse_results(text):\n",
    "        words = [w.lower().strip().replace(\".\", \"\") for w in text.split(\",\")]\n",
    "        return list(set(words))\n",
    "\n",
    "    parsed_tokens = [parse_results(res) for key, res in pred_dict.items()]\n",
    "\n",
    "    # convert the parsed tokens into one-hot predictions\n",
    "    import numpy as np\n",
    "    preds = []\n",
    "    labels = []\n",
    "    eval_idv_answers = []\n",
    "    question_cluster_size = []\n",
    "    question_cluster = []\n",
    "    question_ids = []\n",
    "\n",
    "#     for (key, item), ans in tqdm(zip(data_dict.items(), parsed_tokens)):\n",
    "    for key in data_dict:\n",
    "        item, ans = data_dict[key], parse_results(pred_dict[key])\n",
    "        preds.append([1 if t.lower() in ans and t != \"none\" else 0 for t in item['context']])\n",
    "        labels.append(item[\"answers\"][\"labels\"])\n",
    "        eval_idv_answers.append([a['labels'] for a in item['individual_answers']])\n",
    "        question_cluster_size.append(item['cluster_size'])\n",
    "        question_cluster.append(item[\"question_cluster\"])\n",
    "        question_ids.append(key)\n",
    "    question_ids = [q for i, q in enumerate(question_ids) for x in range(len(labels[i]))]\n",
    "\n",
    "    from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "\n",
    "    label_map = {0: 'Negative', 1: 'Positive'}\n",
    "    eval_loss, eval_accuracy, nb_eval_examples, nb_eval_steps = 0.0, 0.0, 0, 0\n",
    "    all_preds, all_golds, max_f1s, macro_f1s = [], [], [], []\n",
    "    f1_dist = defaultdict(list)\n",
    "    em_counter = 0\n",
    "    em_cluster_agg, em_cluster_relaxed, f1_cluster_80 = {}, {}, {}\n",
    "\n",
    "    for idx in range(len(data_dict)):\n",
    "\n",
    "        pred = preds[idx]\n",
    "        all_preds.extend(pred)\n",
    "        label = labels[idx]\n",
    "        all_golds.extend(label)\n",
    "        pred_names = [label_map[p] for p in pred]\n",
    "        gold_names = [label_map[l] for l in label]\n",
    "        is_em = (pred_names == gold_names)\n",
    "\n",
    "        if sum(label) == 0 and sum(pred) == 0:\n",
    "            macro_f1s.append(1.0)\n",
    "        else:\n",
    "            macro_f1s.append(cal_f1(pred_names, gold_names, {v:k for k,v in label_map.items()}))\n",
    "\n",
    "        max_f1, instance_matched = 0, 0\n",
    "        for gold in eval_idv_answers[idx]:\n",
    "            label_names = [label_map[l] for l in gold]\n",
    "            if pred_names == label_names: instance_matched = 1\n",
    "            if sum(gold) == 0 and sum(pred) == 0:\n",
    "                f1 = 1.0\n",
    "            else:\n",
    "                f1 = cal_f1(pred_names, label_names, {v:k for k,v in label_map.items()})\n",
    "            # if f1 > max_f1: max_f1 = f1\n",
    "            if f1 >= max_f1:\n",
    "                max_f1 = f1\n",
    "                key = len(gold)\n",
    "\n",
    "        if question_cluster_size[idx] > 1:\n",
    "            if question_cluster[idx] not in em_cluster_agg:\n",
    "                em_cluster_agg[question_cluster[idx]] = 1\n",
    "            if is_em == 0: em_cluster_agg[question_cluster[idx]] = 0\n",
    "\n",
    "            if question_cluster[idx] not in em_cluster_relaxed:\n",
    "                em_cluster_relaxed[question_cluster[idx]] = 1\n",
    "            if instance_matched == 0: em_cluster_relaxed[question_cluster[idx]] = 0\n",
    "\n",
    "            if question_cluster[idx] not in f1_cluster_80:\n",
    "                f1_cluster_80[question_cluster[idx]] = 1\n",
    "            if max_f1 < 0.8: f1_cluster_80[question_cluster[idx]] = 0\n",
    "\n",
    "        max_f1s.append(max_f1)\n",
    "        em_counter += instance_matched\n",
    "        f1_dist[key].append(max_f1)\n",
    "\n",
    "    assert len(all_preds) == len(question_ids)\n",
    "    assert len(f1_cluster_80) == len(em_cluster_agg) \n",
    "\n",
    "    # em = exact_match(question_ids, all_golds, all_preds)\n",
    "    eval_accuracy = eval_accuracy / len(all_preds)\n",
    "    label_names = [label_map[l] for l in all_golds]\n",
    "    pred_names = [label_map[p] for p in all_preds]\n",
    "    # eval_pos_f1 = cal_f1(pred_names, label_names, {v:k for k,v in label_map.items()})\n",
    "\n",
    "    em_cluster_relaxed_res = sum(em_cluster_relaxed.values()) / len(em_cluster_relaxed)\n",
    "    em_cluster_agg_res = sum(em_cluster_agg.values()) / len(em_cluster_agg)\n",
    "    f1_cluster_80_res = sum(f1_cluster_80.values()) / len(f1_cluster_80)\n",
    "\n",
    "    label_names = [label_map[l] for l in all_golds]\n",
    "    pred_names = [label_map[p] for p in all_preds]\n",
    "\n",
    "    em = exact_match(question_ids, label_names, pred_names)\n",
    "    eval_pos_f1 = cal_f1(pred_names, label_names, {v:k for k,v in label_map.items()})\n",
    "\n",
    "\n",
    "    print(f\"Eval on the current eval positive class Micro F1 (Agg) is: %.4f\" % eval_pos_f1)\n",
    "    print(f\"Eval on the current eval positive class Macro F1 (Relaxed) is: %.4f\" % np.mean(max_f1s)) # output F1\n",
    "    print(f\"Eval on the current eval positive class Macro F1 (Agg) is: %.4f\" % np.mean(macro_f1s))\n",
    "\n",
    "    print(f\"Eval on the current eval exact match (Agg) ratio is: %.4f\" % em)\n",
    "    print(f\"Eval on the current eval exact match ratio (Relaxed) is: %.4f\" % (em_counter / len(data_dict))) # output EM\n",
    "\n",
    "    print(f\"Eval on %d Clusters\" % len(em_cluster_relaxed))\n",
    "    print(f\"Eval on the current eval clustered EM (Agg) is: %.4f\" % (em_cluster_agg_res))\n",
    "    print(f\"Eval on the current eval clustered EM (Relaxed) is: %.4f\" % (em_cluster_relaxed_res))\n",
    "    print(f\"Eval on the current eval clusrered F1 (max>=0.8) is: %.4f\" % (f1_cluster_80_res)) # consistency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e437c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
