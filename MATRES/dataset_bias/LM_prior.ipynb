{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa-large to check event relations without context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "e1 = \"arrest\"\n",
    "e2 = \"kill\"\n",
    "\n",
    "\n",
    "relation_token_ids = {\"before\":tokenizer.encode(\"before\", add_special_tokens=False)[0],\n",
    "                      \"after\":tokenizer.encode(\"after\", add_special_tokens=False)[0],\n",
    "                      \"equal\":tokenizer.encode(\"during\", add_special_tokens=False)[0]\n",
    "                    }\n",
    "\n",
    "with torch.no_grad():\n",
    "  text = f\"{e1} happens {tokenizer.mask_token} {e2}\"\n",
    "  input = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "  mask_token_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)[0]\n",
    "  token_logits = model(**input).logits\n",
    "  mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "  mask_token_softmax = F.softmax(mask_token_logits, dim=1)\n",
    "  max_idx = torch.argmax(mask_token_softmax[0][[relation_token_ids[\"before\"], relation_token_ids[\"after\"], relation_token_ids[\"equal\"]]])\n",
    "  pred_relation = list(relation_token_ids.keys())[max_idx]\n",
    "  print(pred_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_shot_mlm(e1, e2):\n",
    "    with torch.no_grad():\n",
    "        text = f\"{e1} happens {tokenizer.mask_token} {e2}\"\n",
    "        input = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "        mask_token_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)[0]\n",
    "        token_logits = model(**input).logits\n",
    "        mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "        mask_token_softmax = F.softmax(mask_token_logits, dim=1)\n",
    "        max_idx = torch.argmax(mask_token_softmax[0][[relation_token_ids[\"before\"], relation_token_ids[\"after\"], relation_token_ids[\"equal\"]]])\n",
    "        pred_relation = list(relation_token_ids.keys())[max_idx]\n",
    "        return pred_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6404/6404 [04:00<00:00, 26.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "features_eval = json.load(open(\"../data/valid_text_features_matres.json\", \"r\"))\n",
    "\n",
    "for feat in tqdm(features_eval):\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    pred_relation = zero_shot_mlm(e1, e2)\n",
    "    feat[\"pred_relation\"] = pred_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eval = json.load(open(\"../data/valid_text_features_matres.json\", \"r\"))\n",
    "\n",
    "num_dict = {0: \"before\", 1: \"after\", 2: \"equal\", 3: \"vague\"}\n",
    "pred_2_num = {\"before\":0, \"after\":1, \"equal\":2}\n",
    "\n",
    "pred = [pred_2_num[feat[\"pred_relation\"]] for feat in features_eval]\n",
    "labels = [feat[\"labels\"][0] for feat in features_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39693941286695816, 0.21949467496720393, 0.39693941286695816)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy_score(labels, pred), f1_score(labels, pred, average=\"macro\"), f1_score(labels, pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this to select eval set. Select those predictions are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_bias_conflict = [i for i, feat in enumerate(features_eval) if pred_2_num[feat['pred_relation']] != feat[\"labels\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"../dataset_bias/valid_text_features_matres_roberta_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(features_eval)[roberta_bias_conflict]), writer)\n",
    "numerical_eval_features = json.load(open(\"../data/valid_features_matres.json\", \"r\"))\n",
    "with open(\"../dataset_bias/valid_features_matres_roberta_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(numerical_eval_features)[roberta_bias_conflict]), writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'google/bigbird-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BigBirdForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "del model\n",
    "gc.collect()\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-large')\n",
    "model = AutoModelForMaskedLM.from_pretrained('google/bigbird-roberta-large').to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6404 [00:00<?, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 6 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "100%|██████████| 6404/6404 [04:36<00:00, 23.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# features_eval = json.load(open(\"../data/valid_text_features_matres.json\", \"r\"))\n",
    "\n",
    "for feat in tqdm(features_eval):\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    pred_relation = zero_shot_mlm(e1, e2)\n",
    "    feat[\"pred_relation_bigbird\"] = pred_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35446595877576514, 0.14704040903554233, 0.3544659587757651)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "pred_bigbird = [pred_2_num[feat[\"pred_relation_bigbird\"]] for feat in features_eval]\n",
    "accuracy_score(labels, pred_bigbird), f1_score(labels, pred_bigbird, average=\"macro\"), f1_score(labels, pred_bigbird, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigbird_bias_conflict = [i for i, feat in enumerate(features_eval) if pred_2_num[feat['pred_relation_bigbird']] != feat[\"labels\"][0]]\n",
    "with open(\"../dataset_bias/valid_features_matres_bigbird_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(numerical_eval_features)[bigbird_bias_conflict]), writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2969\n"
     ]
    }
   ],
   "source": [
    "# both incorrect\n",
    "\n",
    "both_bias_conflict = [i for i, feat in enumerate(features_eval) if pred_2_num[feat['pred_relation_bigbird']] != feat[\"labels\"][0] and pred_2_num[feat['pred_relation']] != feat[\"labels\"][0]]\n",
    "print(len(both_bias_conflict))                      \n",
    "with open(\"../dataset_bias/valid_features_matres_both_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(numerical_eval_features)[both_bias_conflict]), writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-large')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained('gpt2-large').to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "features_eval = json.load(open(\"../data/valid_text_features_matres.json\", \"r\"))\n",
    "\n",
    "num_dict = {0: \"before\", 1: \"after\", 2: \"equal\", 3: \"vague\"}\n",
    "pred_2_num = {\"before\":0, \"after\":1, \"equal\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_loss = torch.nn.functional.cross_entropy\n",
    "def get_perplexity(text):\n",
    "    with torch.no_grad():\n",
    "        input = tokenizer(text, return_tensors=\"pt\", padding=\"longest\").to(\"cuda\")\n",
    "        ids = input[\"input_ids\"]\n",
    "        mask = input[\"attention_mask\"]\n",
    "\n",
    "        input[\"labels\"] = input[\"input_ids\"]\n",
    "\n",
    "        outputs = model(**input)\n",
    "\n",
    "        shift_logits = outputs[1][..., :-1, :].contiguous().view(-1,outputs[1].size(-1))\n",
    "        shift_labels = ids[..., 1:].contiguous().view(-1)\n",
    "            \n",
    "        loss = cr_loss(shift_logits, shift_labels, \n",
    "                    ignore_index=tokenizer.pad_token_id, reduction=\"none\").view(ids.size(0), -1)\n",
    "\n",
    "        loss = torch.div(torch.sum(loss, dim=1), torch.sum(mask[:, 1:], dim=1))\n",
    "\n",
    "    return loss.cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rel_relations = {\"before\":\"before\", \"after\":\"after\", \"equal\":\"during\"}\n",
    "def zero_shot_gpt2(e1, e2):\n",
    "   with torch.no_grad():\n",
    "      text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()]\n",
    "      loss = get_perplexity(text)\n",
    "      max_idx = np.argmin(loss) # get the smallest loss\n",
    "      pred_relation = list(temp_rel_relations.keys())[max_idx]\n",
    "      return pred_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.072517395019531, 9.05626106262207, 9.474804878234863]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = \"arrest\"\n",
    "e2 = \"kill\"\n",
    "text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()]\n",
    "input = tokenizer(text, return_tensors=\"pt\", padding=\"longest\").to(\"cuda\")\n",
    "get_perplexity(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6404/6404 [04:37<00:00, 23.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "for feat in tqdm(features_eval):\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    pred_relation = zero_shot_gpt2(e1, e2)\n",
    "    feat[\"pred_relation_gpt2\"] = pred_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36961274203622735, 0.21597823874693078, 0.3696127420362274)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "labels = [feat[\"labels\"][0] for feat in features_eval]\n",
    "pred_gpt2 = [pred_2_num[feat[\"pred_relation_gpt2\"]] for feat in features_eval]\n",
    "accuracy_score(labels, pred_gpt2), f1_score(labels, pred_gpt2, average=\"macro\"), f1_score(labels, pred_gpt2, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.36961274203622735, 0.21597823874693078, 0.3696127420362274)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_gpt2 = [pred_2_num[feat[\"pred_relation_gpt2\"]] for feat in features_eval]\n",
    "accuracy_score(labels, pred_gpt2), f1_score(labels, pred_gpt2, average=\"macro\"), f1_score(labels, pred_gpt2, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bias_conflict = [i for i, feat in enumerate(features_eval) if pred_2_num[feat['pred_relation_bigbird']] != feat[\"labels\"][0] and pred_2_num[feat['pred_relation']] != feat[\"labels\"][0] and pred_2_num[feat['pred_relation_gpt2']] != feat[\"labels\"][0]]\n",
    "# with open(\"../dataset_bias/valid_features_matres_all_erp_bias.json\", \"w\") as writer:\n",
    "#     json.dump(list(np.array(numerical_eval_features)[all_bias_conflict]), writer)\n",
    "with open(\"../dataset_bias/valid_text_features_matres_all_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(features_eval)[all_bias_conflict]), writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_conflict = [i for i, feat in enumerate(features_eval) if pred_2_num[feat['pred_relation_gpt2']] != feat[\"labels\"][0]]\n",
    "with open(\"../dataset_bias/valid_text_features_matres_gpt2_erp_bias.json\", \"w\") as writer:\n",
    "    json.dump(list(np.array(features_eval)[gpt2_conflict]), writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 1600)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2-xl')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model =  AutoModelForCausalLM.from_pretrained('gpt2-xl').to(\"cuda\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "features_eval = json.load(open(\"../data/valid_text_features_matres.json\", \"r\"))\n",
    "\n",
    "num_dict = {0: \"before\", 1: \"after\", 2: \"equal\", 3: \"vague\"}\n",
    "pred_2_num = {\"before\":0, \"after\":1, \"equal\":2}\n",
    "\n",
    "cr_loss = torch.nn.functional.cross_entropy\n",
    "def get_perplexity(text):\n",
    "    with torch.no_grad():\n",
    "        input = tokenizer(text, return_tensors=\"pt\", padding=\"longest\").to(\"cuda\")\n",
    "        ids = input[\"input_ids\"]\n",
    "        mask = input[\"attention_mask\"]\n",
    "\n",
    "        input[\"labels\"] = input[\"input_ids\"].detach().clone()\n",
    "\n",
    "        outputs = model(**input)\n",
    "\n",
    "        shift_logits = outputs[1][..., :-1, :].contiguous().view(-1,outputs[1].size(-1))\n",
    "        shift_labels = ids[..., 1:].contiguous().view(-1)\n",
    "            \n",
    "        loss = cr_loss(shift_logits, shift_labels, \n",
    "                    ignore_index=tokenizer.pad_token_id, reduction=\"none\").view(ids.size(0), -1)\n",
    "\n",
    "        loss = torch.div(torch.sum(loss, dim=1), torch.sum(mask[:, 1:], dim=1))\n",
    "\n",
    "    return loss.cpu().tolist()\n",
    "\n",
    "temp_rel_relations = {\"before\":\"before\", \"after\":\"after\", \"equal\":\"during\"}\n",
    "def zero_shot_gpt2(e1, e2):\n",
    "   with torch.no_grad():\n",
    "      text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()]\n",
    "      loss = get_perplexity(text)\n",
    "      max_idx = np.argmin(loss) # get the smallest loss\n",
    "      pred_relation = list(temp_rel_relations.keys())[max_idx]\n",
    "      return pred_relation\n",
    "def zero_shot_gpt2_softmax(e1, e2):\n",
    "   with torch.no_grad():\n",
    "      text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()]\n",
    "      loss = get_perplexity(text)\n",
    "      max_idx = np.argmin(loss) # get the smallest loss\n",
    "      pred_relation = list(temp_rel_relations.keys())[max_idx]\n",
    "      return pred_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eval = json.load(open(\"../data/valid_subset_text.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. simple perplexity\n",
    "for feat in tqdm(features_eval):\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    pred_relation = zero_shot_gpt2(e1, e2)\n",
    "    feat[\"pred_relation_gpt2_xl\"] = pred_relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:26<00:00, 11.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# 2. get new probabilities\n",
    "\n",
    "\n",
    "for feat in tqdm(features_eval):\n",
    "\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()] + [f\"{e2} happens {r} {e1}\" for r in temp_rel_relations.values()]\n",
    "    ppls = get_perplexity(text)\n",
    "    p = {\n",
    "        \"before\": np.exp(-ppls[0]) + np.exp(-ppls[4]),\n",
    "        \"after\": np.exp(-ppls[1]) + np.exp(-ppls[3]),\n",
    "        \"equal\": np.exp(-ppls[2]) + np.exp(-ppls[5])\n",
    "    }\n",
    "    feat[\"ppls_gpt2_xl\"] = json.dumps(p)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_ppl(feat):\n",
    "    return sorted(json.loads(feat[\"ppls_gpt2_xl\"]).items(), key=lambda x:x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2xl_pred = [pred_2_num[get_pred_ppl(feat)] for feat in features_eval]\n",
    "labels = [feat[\"labels\"][0] for feat in features_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "0.19001982690285615 0.34\n"
     ]
    }
   ],
   "source": [
    "# original accuracy\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "print(\"original\")\n",
    "print(f1_score(labels, gpt2xl_pred, average='macro'), f1_score(labels, gpt2xl_pred, average=\"micro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2xl_subset_idx = [i for i in range(len(labels)) if gpt2xl_pred[i]!=labels[i]]\n",
    "np.save(\"gpt2xl_subset_idx\", gpt2xl_subset_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n"
     ]
    }
   ],
   "source": [
    "gpt2xl_subset_idx_hard = [i for i in range(len(labels)) \\\n",
    "                if gpt2xl_pred[i]!=labels[i] and sorted(features_eval[i][\"gpt2xl_ppl_norm\"].values())[-1] - sorted(features_eval[i][\"gpt2xl_ppl_norm\"].values())[0] > 0.15]\n",
    "print(len(gpt2xl_subset_idx_hard))\n",
    "np.save(\"gpt2xl_subset_idx_hard\", gpt2xl_subset_idx_hard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 25696.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for feat in tqdm(features_eval):\n",
    "    feat[\"gpt2xl_ppl_norm\"] = dict([(key, val/sum(json.loads(feat[\"ppls_gpt2_xl\"]).values()) ) for key, val in json.loads(feat[\"ppls_gpt2_xl\"]).items()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.hist([sorted(features_eval[i][\"gpt2xl_ppl_norm\"].values())[-1] - sorted(features_eval[i][\"gpt2xl_ppl_norm\"].values())[0] for i in range(len(features_eval))] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6336/6336 [08:56<00:00, 11.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "\n",
    "train_features_text = json.load(open(\"../data/train_text_features_matres.json\"))\n",
    "\n",
    "for feat in tqdm(train_features_text):\n",
    "\n",
    "    e1 = feat[\"e1\"]\n",
    "    e2 = feat[\"e2\"]\n",
    "    text = [f\"{e1} happens {r} {e2}\" for r in temp_rel_relations.values()] + [f\"{e2} happens {r} {e1}\" for r in temp_rel_relations.values()]\n",
    "    ppls = get_perplexity(text)\n",
    "    p = {\n",
    "        \"before\": np.exp(-ppls[0]) + np.exp(-ppls[4]),\n",
    "        \"after\": np.exp(-ppls[1]) + np.exp(-ppls[3]),\n",
    "        \"equal\": np.exp(-ppls[2]) + np.exp(-ppls[5])\n",
    "    }\n",
    "    feat[\"ppls_gpt2_xl\"] = json.dumps(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6336/6336 [00:00<00:00, 40965.52it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for feat in tqdm(train_features_text):\n",
    "    feat[\"gpt2xl_ppl_norm\"] = dict([(key, val/sum(json.loads(feat[\"ppls_gpt2_xl\"]).values()) ) for key, val in json.loads(feat[\"ppls_gpt2_xl\"]).items()])\n",
    "    \n",
    "\n",
    "plt.hist([sorted(train_features_text[i][\"gpt2xl_ppl_norm\"].values())[-1] - sorted(train_features_text[i][\"gpt2xl_ppl_norm\"].values())[0] for i in range(len(train_features_text))] )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n"
     ]
    }
   ],
   "source": [
    "labels_train = [feat[\"labels\"][0] for feat in train_features_text]\n",
    "gpt2xl_pred_train = [pred_2_num[get_pred_ppl(feat)] for feat in train_features_text]\n",
    "\n",
    "gpt2xl_subset_idx_hard_train = [i for i in range(len(train_features_text)) \\\n",
    "                if gpt2xl_pred_train[i]!=labels_train[i] and sorted(train_features_text[i][\"gpt2xl_ppl_norm\"].values())[-1] - sorted(train_features_text[i][\"gpt2xl_ppl_norm\"].values())[0] > 0.15]\n",
    "print(len(gpt2xl_subset_idx_hard_train))\n",
    "np.save(\"gpt2xl_subset_idx_hard_train\", gpt2xl_subset_idx_hard_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
