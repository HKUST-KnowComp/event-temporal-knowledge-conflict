{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da421331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time = 03/11/2023 03:27:31\n",
      "Processing MATRES dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BigBirdModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "from datetime import datetime \n",
    "import random\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from torch.utils.data import DataLoader\n",
    "from util import *\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from exp import *\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "from synonyms import *\n",
    "import pickle\n",
    "from timeline_construct import *\n",
    "from ts import func, ModelWithTemperature\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.datetime.now()\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = now.strftime(\"%m/%d/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "#label_dict={\"SuperSub\": 0, \"SubSuper\": 1, \"Coref\": 2, \"NoRel\": 3}\n",
    "num_dict = {0: \"before\", 1: \"after\", 2: \"equal\", 3: \"vague\"}\n",
    "\n",
    "mask_in_input_ids = 0 # note that [MASK] is actually learned through pre-training\n",
    "mask_in_input_mask = 0 # when input is masked through attention, it would be replaced with [PAD]\n",
    "acronym = 0 # using acronym for tense (e.g., pastsimp): 1; else (e.g., past simple): 0\n",
    "t_marker = 1\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    max_len = max([len(f['input_ids']) for f in batch])\n",
    "    input_ids = [f['input_ids'] + [0] * (max_len - len(f['input_ids'])) for f in batch]\n",
    "    if mask_in_input_ids:\n",
    "        input_ids_new = []\n",
    "        for f_id, f in enumerate(input_ids):\n",
    "            for event_id, start in enumerate(batch[f_id]['event_pos']):\n",
    "                end = batch[f_id]['event_pos_end'][event_id]\n",
    "                for token_id in range(start, end): # needs verification\n",
    "                    f[token_id] = 67\n",
    "            input_ids_new.append(f)\n",
    "        input_ids = input_ids_new\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "    input_mask = [[1.0] * len(f['input_ids']) + [0.0] * (max_len - len(f['input_ids'])) for f in batch]\n",
    "    if mask_in_input_mask:\n",
    "        input_mask_new = []\n",
    "        for f_id, f in enumerate(input_mask):\n",
    "            for event_id, start in enumerate(batch[f_id]['event_pos']):\n",
    "                end = batch[f_id]['event_pos_end'][event_id]\n",
    "                for token_id in range(start, end): # needs verification\n",
    "                    f[token_id] = 0.0\n",
    "            input_mask_new.append(f)\n",
    "        input_mask = input_mask_new\n",
    "    # Updated on May 17, 2022    \n",
    "    input_mask_eo = [[0.0] * max_len for f in batch]\n",
    "    for f_id, f in enumerate(input_mask_eo):\n",
    "        for event_id, start in enumerate(batch[f_id]['event_pos']):\n",
    "            end = batch[f_id]['event_pos_end'][event_id]\n",
    "            for token_id in range(start, end): # needs verification\n",
    "                f[token_id] = 1.0\n",
    "    # Updated on Jun 14, 2022\n",
    "    input_mask_xbar = [[0.0] * max_len for f in batch]\n",
    "    input_mask_xbar = torch.tensor(input_mask_xbar, dtype=torch.float)\n",
    "    input_mask_eo = torch.tensor(input_mask_eo, dtype=torch.float)\n",
    "    input_mask = torch.tensor(input_mask, dtype=torch.float)\n",
    "    event_pos = [f['event_pos'] for f in batch]\n",
    "    event_pos_end = [f['event_pos_end'] for f in batch]\n",
    "    event_pair = [f['event_pair'] for f in batch]\n",
    "    labels = [f['labels'] for f in batch]\n",
    "    output = (input_ids, input_mask, event_pos, event_pos_end, event_pair, labels, input_mask_eo, input_mask_xbar)\n",
    "    return output\n",
    "\n",
    "#############################\n",
    "### Setting up parameters ###\n",
    "#############################\n",
    "f1_metric = 'micro'\n",
    "params = {'transformers_model': 'google/bigbird-roberta-large',\n",
    "          'dataset': 'MATRES',   # 'HiEve', 'IC', 'MATRES' \n",
    "          'testdata': 'None', # MATRES / MATRES_nd / TDD / PRED / None; None means training mode\n",
    "          'block_size': 64,\n",
    "          'add_loss': 0, \n",
    "          'batch_size': 4,    # 6 works on 48G gpu. In the paper: 20 \n",
    "          'accum_iter':5,\n",
    "          'epochs': 1,\n",
    "          'learning_rate': 5e-6,    # subject to change\n",
    "          'seed': 0,\n",
    "          'gpu_id': '11453',    # subject to change\n",
    "          'debug': 0,\n",
    "          'rst_file_name': 'init_test.rst',    # subject to change\n",
    "          'mask_in_input_ids': mask_in_input_ids,\n",
    "          'mask_in_input_mask': mask_in_input_mask,\n",
    "          'marker': 'abc', \n",
    "          'tense_acron': 0, # 1 (acronym of tense) or 0 (original tense)\n",
    "          't_marker': 1, # 2 (trigger enclosed by special tokens) or 1 (tense enclosed by **)\n",
    "          'td': 1, # 0 (no tense detection) or 1 (tense detection, add tense info)\n",
    "          'dpn': 0, # 1 if use DPN; else 0\n",
    "          'lambda_1': -10, # lower bound * 10\n",
    "          'lambda_2': 11, # upper bound * 10\n",
    "          'f1_metric': f1_metric, \n",
    "         }\n",
    "# $acr $tmarker $td $dpn $mask $lambda_1 $lambda_2\n",
    "\n",
    "# FOR 48GBgpu\n",
    "if params['testdata'] in ['MATRES', 'MATRES_nd']:\n",
    "    #params['batch_size'] = 400\n",
    "    params['batch_size'] = 1\n",
    "if params['testdata'] in ['TDD']:\n",
    "    params['batch_size'] = 100\n",
    "    \n",
    "if params['testdata'] == 'MATRES_nd':\n",
    "    params['nd'] = True\n",
    "else:\n",
    "    params['nd'] = False\n",
    "\n",
    "if params['transformers_model'][-5:] == \"large\":\n",
    "    params['emb_size'] = 1024\n",
    "elif params['transformers_model'][-4:] == \"base\":\n",
    "    params['emb_size'] = 768\n",
    "else:\n",
    "    print(\"emb_size is neither 1024 nor 768? ...\")\n",
    "    \n",
    "set_seed(params['seed'])\n",
    "rst_file_name = params['rst_file_name']\n",
    "\"\"\"\n",
    "model_params_dir = \"./model_params/\"\n",
    "if params['dataset'] == 'HiEve':\n",
    "    best_PATH = model_params_dir + \"HiEve_best/\" + rst_file_name.replace(\".rst\", \".pt\") # to save model params here\n",
    "elif params['dataset'] == 'IC':\n",
    "    best_PATH = model_params_dir + \"IC_best/\" + rst_file_name.replace(\".rst\", \".pt\") # to save model params here\n",
    "elif params['dataset'] == 'MATRES':\n",
    "    best_PATH = model_params_dir + \"MATRES_best/\" + rst_file_name.replace(\".rst\", \".pt\") # to save model params here\n",
    "else:\n",
    "    print(\"Dataset unknown...\")\n",
    "\"\"\"\n",
    "best_PATH = sys.argv[1] + '/' + '0511.pt' \n",
    "model_name = rst_file_name.replace(\".rst\", \"\")\n",
    "with open(\"config/\" + rst_file_name.replace(\"rst\", \"json\"), 'w') as config_file:\n",
    "    json.dump(params, config_file)\n",
    "    \n",
    "if int(params['gpu_id']) < 10:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = params['gpu_id']\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "cuda = torch.device('cuda')\n",
    "params['cuda'] = cuda # not included in config file\n",
    "\n",
    "#######################\n",
    "### Data processing ###\n",
    "#######################\n",
    "\n",
    "print(\"Processing \" + params['dataset'] + \" dataset...\")\n",
    "t0 = time.time()\n",
    "if params['dataset'] == \"IC\":\n",
    "    dir_name = \"./IC/IC_Processed/\"\n",
    "    #max_sent_len = 193\n",
    "elif params['dataset'] == \"HiEve\":\n",
    "    dir_name = \"./hievents_v2/processed/\"\n",
    "    #max_sent_len = 155\n",
    "elif params['dataset'] == \"MATRES\":\n",
    "    dir_name = \"\"\n",
    "else:\n",
    "    print(\"Not supporting this dataset yet!\")\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(params['transformers_model'])   \n",
    "if acronym:\n",
    "    special_tokens_dict = {'additional_special_tokens': \n",
    "                           [' [futuperfsimp]',' [futucont]',' [futuperfcont]',' [futusimp]', ' [pastcont]', ' [pastperfcont]', ' [pastperfsimp]', ' [pastsimp]', ' [prescont]', ' [presperfcont]', ' [presperfsimp]', ' [pressimp]', ' [futuperfsimppass]',' [futucontpass]',' [futuperfcontpass]',' [futusimppass]', ' [pastcontpass]', ' [pastperfcontpass]', ' [pastperfsimppass]', ' [pastsimppass]', ' [prescontpass]', ' [presperfcontpass]', ' [presperfsimppass]', ' [pressimppass]', ' [none]'\n",
    "                           ]}\n",
    "    spec_toke_list = []\n",
    "    for t in special_tokens_dict['additional_special_tokens']:\n",
    "        spec_toke_list.append(\" [/\" + t[2:])\n",
    "    special_tokens_dict['additional_special_tokens'] += spec_toke_list\n",
    "    num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model = AutoModel.from_pretrained(params['transformers_model'])\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "else:\n",
    "    model = AutoModel.from_pretrained(params['transformers_model'])\n",
    "params['model'] = model\n",
    "debug = params['debug']\n",
    "if debug:\n",
    "    params['epochs'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e065ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Data processing took: 0:00:08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "features_train = json.load(open(\"./data/train_features_matres_with_tense.json\"))\n",
    "features_valid = json.load(open(\"./data/valid_features_matres_with_tense.json\"))\n",
    "features_test = json.load(open(\"./data/test_features_matres_with_tense.json\"))\n",
    "\n",
    "remove_list = [\"being\", \"doing\", \"having\", \"'ve\", \"'re\", \"did\", \"'s\", \"are\", \"is\", \"am\", \"was\", \"were\", \"been\", \"had\", \"said\", \"be\", \"have\", \"can\", \"could\", \"may\", \"might\", \"must\", \"ought\", \"shall\", \"will\", \"would\", \"say\", \"nee\", \"need\", \"do\", \"happen\", \"occur\"]\n",
    "\n",
    "\n",
    "if debug:\n",
    "    train_dataloader = DataLoader(features_train, batch_size=params['batch_size'], shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    valid_dataloader = test_dataloader = train_dataloader\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        print(batch)\n",
    "elif params['testdata'] == 'TDD':\n",
    "    features_valid, labels_valid, labels_full_valid = TDD_processor('man-dev')\n",
    "    features_test, labels_test, labels_full_test = TDD_processor('man-test')\n",
    "    valid_dataloader = DataLoader(features_valid, batch_size=params['batch_size'], shuffle=False, collate_fn=collate_fn, drop_last=False) \n",
    "    test_dataloader = DataLoader(features_test, batch_size=params['batch_size'], shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "elif params['testdata'] == 'PRED':\n",
    "    test_dataloader = DataLoader(features_test, batch_size=params['batch_size'], shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "else:\n",
    "    train_dataloader = DataLoader(features_train, batch_size=params['batch_size'], shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "    valid_dataloader = DataLoader(features_valid, batch_size=params['batch_size'], shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "    test_dataloader = DataLoader(features_test, batch_size=params['batch_size'], shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "print(\"  Data processing took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e4ad61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of parameters: 364635144\n"
     ]
    }
   ],
   "source": [
    "from model import transformers_mlp_cons\n",
    "\n",
    "\n",
    "OnePassModel = transformers_mlp_cons(params)\n",
    "OnePassModel.to(cuda)\n",
    "OnePassModel.zero_grad()\n",
    "print(\"# of parameters:\", count_parameters(OnePassModel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6024cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PREDICTING MODE\n",
    "best_F1 = 0.0\n",
    "\n",
    "mem_exp_test = exp(cuda, OnePassModel, params['epochs'], params['learning_rate'], \n",
    "                   train_dataloader, valid_dataloader, test_dataloader, \n",
    "                   params['dataset'], best_PATH, None, params['dpn'], model_name, \n",
    "                   relation_stats=None, lambdas=None, accum_iter=params[\"accum_iter\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594a4103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Attention type 'block_sparse' is not possible if sequence_length: 198 <= num global tokens: 2 * config.block_size + min. num sliding tokens: 3 * config.block_size + config.num_random_blocks * config.block_size + additional buffer: config.num_random_blocks * config.block_size = 704 with config.block_size = 64, config.num_random_blocks = 3. Changing attention type to 'original_full'...\n",
      "200it [00:54,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    316.    Elapsed: 0:00:54.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [01:44,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    80  of    316.    Elapsed: 0:01:44.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [02:33,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   120  of    316.    Elapsed: 0:02:33.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800it [03:22,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   160  of    316.    Elapsed: 0:03:22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [04:11,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    316.    Elapsed: 0:04:12.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1200it [05:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   240  of    316.    Elapsed: 0:05:01.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [05:50,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   280  of    316.    Elapsed: 0:05:50.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1584it [06:35,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Total training loss: 1818.22\n",
      "  Training epoch took: 0:06:35\n",
      "\n",
      "Running Evaluation on Validation Set...\n",
      "Eval took: 0:01:29\n",
      "  P: 0.793\n",
      "  R: 0.730\n",
      "  F1: 0.760\n",
      "  macro f-score: 0.444\n",
      "  micro f-score: 0.686\n",
      "[[2611  160    0  462]\n",
      " [ 305 1572    0  386]\n",
      " [ 112   48    0   72]\n",
      " [ 297  169    0  210]]\n",
      "No classification_report for this epoch of evaluation (Recall and F-score are ill-defined and being set to 0.0 due to no true samples).\n",
      "\n",
      "======== Training complete! ========\n",
      "Total training took 0:08:04 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1e-06, -1e-06)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_exp_test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea75884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Evaluation on Validation Set...\n",
      "Eval took: 0:01:28\n",
      "  P: 0.793\n",
      "  R: 0.730\n",
      "  F1: 0.760\n",
      "  macro f-score: 0.444\n",
      "  micro f-score: 0.686\n",
      "[[2611  160    0  462]\n",
      " [ 305 1572    0  386]\n",
      " [ 112   48    0   72]\n",
      " [ 297  169    0  210]]\n",
      "No classification_report for this epoch of evaluation (Recall and F-score are ill-defined and being set to 0.0 due to no true samples).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0.7604071986911471)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_exp_test.evaluate(mem_exp_test.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d031d835",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [

     ]
    }
   ],
   "source": [,
    "torch.save(OnePassModel.state_dict(), output_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff85a4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7928862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_features = json.load(open(\"./data/train_features_matres_with_tense.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b17c26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3229, 3: 855, 1: 2044, 2: 208})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "Counter(chain(*[train_features[i]['labels'] for i in range(len(train_features))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f950a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
