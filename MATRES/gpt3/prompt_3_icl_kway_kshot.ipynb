{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43428f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "features_valid = json.load(open(\"../data/valid_subset_text.json\"))\n",
    "features_valid_erp = json.load(open(\"../dataset_bias/valid_subset_text_erp.json\"))\n",
    "features_valid_tense_all = json.load(open(\"../dataset_bias/valid_subset_text_tense_bias_vague.json\"))\n",
    "\n",
    "# features_valid_tense_vague = [item for item in features_valid_tense_all if item['labels'][0] == 3]\n",
    "# features_valid_dep = json.load(open(\"../dataset_bias/valid_text_features_matres_dep_bias.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe89afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dad34001",
   "metadata": {},
   "source": [
    "# ICL, m way, k-shot\n",
    "\n",
    "\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d12f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_text_features_matres.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fb34db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_by_labels = [[item for item in train if item['labels'][0] == i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4316c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(0)\n",
    "examplars_1_shot_0 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([{'text': \"[CLS] Jim Unruh, Unisys's president, said he is approaching next year with caution.[SEP] He said the strength of the world-wide economy is suspect, and doesn't see much revenue growth in the cards.[SEP] He also said that the price wars flaring up in parts of the computer industry will continue through next year.[SEP] He said the move toward standard operating systems means customers aren't locked into buying from their traditional computer supplier and can force prices down.[SEP]\", 'e1': 'suspect', 'e2': 'flaring', 'labels': [0]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] The latest results include some unusual write-downs, which had an after-tax impact of $4.9 million.[SEP] Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989.[SEP] In addition, operating results were hit by an increase in loan and real estate loss reserves.[SEP]', 'e1': 'included', 'e2': 'terminated', 'labels': [1]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] Intel said it had corrected the problems and would start producing bugless chips next week.[SEP] \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip.[SEP] What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom.[SEP] \"These errata do not affect business programs,\" he said.[SEP]', 'e1': 'said', 'e2': 'emerge', 'labels': [2]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] NEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women.[SEP] The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes.[SEP] State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases.[SEP]', 'e1': 'needed', 'e2': 'identified', 'labels': [3]}],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplars_1_shot_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64e8ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplar_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_0[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "    examplar_0.append(prompt)\n",
    "examplar_0 = \"\\n\\n\".join(examplar_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b1a94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fd357ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the document Jim Unruh, Unisys\\'s president, said he is approaching next year with caution. He said the strength of the world-wide economy is suspect, and doesn\\'t see much revenue growth in the cards. He also said that the price wars flaring up in parts of the computer industry will continue through next year. He said the move toward standard operating systems means customers aren\\'t locked into buying from their traditional computer supplier and can force prices down. and a list of temporal relations [before, after, vague, equal] and event triggers suspect and flaring. what is the temporal relation between suspect and flaring? Answer vague if unsure. Keep the answer short and concise. before\\n\\nGiven the document The latest results include some unusual write-downs, which had an after-tax impact of $4.9 million. Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989. In addition, operating results were hit by an increase in loan and real estate loss reserves. and a list of temporal relations [before, after, vague, equal] and event triggers included and terminated. what is the temporal relation between included and terminated? Answer vague if unsure. Keep the answer short and concise. after\\n\\nGiven the document Intel said it had corrected the problems and would start producing bugless chips next week. \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip. What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom. \"These errata do not affect business programs,\" he said. and a list of temporal relations [before, after, vague, equal] and event triggers said and emerge. what is the temporal relation between said and emerge? Answer vague if unsure. Keep the answer short and concise. equal\\n\\nGiven the document NEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women. The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes. State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases. and a list of temporal relations [before, after, vague, equal] and event triggers needed and identified. what is the temporal relation between needed and identified? Answer vague if unsure. Keep the answer short and concise. vague'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplar_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0564bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/prompt_3_icl_examplar_1_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "185489a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [50:44<00:00,  3.04s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_0 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8832b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'BEFORE':0, 'AFTER':1, 'EQUAL':2, 'VAGUE':3}\n",
    "convert_dict_rev = {0:'before', 1:'after', 2:'equal', 3:'vague'}\n",
    "def parse_result(ans):\n",
    "    return convert_dict[ans.upper()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "664ebf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_preds_0 = [parse_result(item['choices'][0]['text'].replace('.', '').strip()) for item in oneshot_results_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e1d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18626754503181908 0.327\n"
     ]
    }
   ],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_0, average='macro'), f1_score(labels, oneshot_preds_0, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d3f2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_3_oneshot_pred_0.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_0, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd00d9a",
   "metadata": {},
   "source": [
    "## run -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "231ff01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_1_shot_1 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_1[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "    examplar_1.append(prompt)\n",
    "examplar_1 = \"\\n\\n\".join(examplar_1)\n",
    "\n",
    "with open(\"prompts/prompt_3_icl_examplar_1_shot_1.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b425dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [51:52<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_1 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84481005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20682353870120082 0.344\n"
     ]
    }
   ],
   "source": [
    "oneshot_preds_1 = [parse_result(item['choices'][0]['text'].replace('.', '').strip()) for item in oneshot_results_1]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_1, average='macro'), f1_score(labels, oneshot_preds_1, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c977792",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_3_oneshot_pred_1.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_1, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886010f",
   "metadata": {},
   "source": [
    "## run-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0760af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_1_shot_2 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_2[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "    examplar_2.append(prompt)\n",
    "examplar_2 = \"\\n\\n\".join(examplar_2)\n",
    "\n",
    "with open(\"prompts/prompt_3_icl_examplar_1_shot_2.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bbf97d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [52:27<00:00,  3.15s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_2 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e143b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1780953431113662 0.288\n"
     ]
    }
   ],
   "source": [
    "oneshot_preds_2 = [parse_result(item['choices'][0]['text'].replace('.', '').strip()) for item in oneshot_results_2]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_2, average='macro'), f1_score(labels, oneshot_preds_2, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18e6269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_3_oneshot_pred_2.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_2, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eabd53",
   "metadata": {},
   "source": [
    "# 3-shot\n",
    "\n",
    "run 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce8a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_3_shot_0 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_0[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "        examplar_3_0.append(prompt)\n",
    "    \n",
    "examplar_3_0 = \"\\n\\n\".join(examplar_3_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/chan_prompt_icl_examplar_3_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffde896",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_0 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c26907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_0]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds, average='macro'), f1_score(labels_selected, threeshot_preds, average=\"micro\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45fa3d4",
   "metadata": {},
   "source": [
    "run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a943eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_3_shot_1 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_1[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "        examplar_3_1.append(prompt)\n",
    "    \n",
    "examplar_3_1 = \"\\n\\n\".join(examplar_3_1)\n",
    "\n",
    "with open(\"prompts/prompt_3_icl_examplar_3_shot_1.txt_saved\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39d1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_1 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4580dfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_pred_1 =  [parse_result(item['choices'][0]['text'].replace('.', '').strip()) for item in threeshot_results_1]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_pred_1, average='macro'), f1_score(labels_selected, threeshot_pred_1, average=\"micro\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd32db",
   "metadata": {},
   "source": [
    "run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae14427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(3)\n",
    "examplars_3_shot_2 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_2[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise. {convert_dict_rev[label]}\"\n",
    "        examplar_3_2.append(prompt)\n",
    "    \n",
    "examplar_3_2 = \"\\n\\n\".join(examplar_3_2)\n",
    "\n",
    "with open(\"prompts/prompt_3_icl_examplar_3_shot_2.txt_saved\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb3864",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_2 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Given the document {context} and a list of temporal relations [before, after, vague, equal] and event triggers {e1} and {e2}. what is the temporal relation between {e1} and {e2}? Answer vague if unsure. Keep the answer short and concise\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce3cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_pred_2 =  [parse_result(item['choices'][0]['text'].replace('.', '').strip()) for item in threeshot_results_2]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_pred_2, average='macro'), f1_score(labels_selected, threeshot_pred_2, average=\"micro\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
