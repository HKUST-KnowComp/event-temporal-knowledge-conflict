{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43428f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "features_valid = json.load(open(\"../data/valid_subset_text.json\"))\n",
    "features_valid_erp = json.load(open(\"../dataset_bias/valid_subset_text_erp.json\"))\n",
    "features_valid_tense_all = json.load(open(\"../dataset_bias/valid_subset_text_tense_bias_vague.json\"))\n",
    "\n",
    "# features_valid_tense_vague = [item for item in features_valid_tense_all if item['labels'][0] == 3]\n",
    "# features_valid_dep = json.load(open(\"../dataset_bias/valid_text_features_matres_dep_bias.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe89afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dad34001",
   "metadata": {},
   "source": [
    "# ICL, m way, k-shot\n",
    "\n",
    "\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f244096",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'A':0, 'B':1, 'C':2, 'D':3}\n",
    "convert_dict_rev = {0:'A', 1:'B', 2:'C', 3:'D'}\n",
    "def parse_result(ans):\n",
    "    return convert_dict.get(ans.upper(), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d12f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_text_features_matres.json\"))\n",
    "train_by_labels = [[item for item in train if item['labels'][0] == i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f98397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4316c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(0)\n",
    "examplars_1_shot_0 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([{'text': \"[CLS] Jim Unruh, Unisys's president, said he is approaching next year with caution.[SEP] He said the strength of the world-wide economy is suspect, and doesn't see much revenue growth in the cards.[SEP] He also said that the price wars flaring up in parts of the computer industry will continue through next year.[SEP] He said the move toward standard operating systems means customers aren't locked into buying from their traditional computer supplier and can force prices down.[SEP]\", 'e1': 'suspect', 'e2': 'flaring', 'labels': [0]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] The latest results include some unusual write-downs, which had an after-tax impact of $4.9 million.[SEP] Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989.[SEP] In addition, operating results were hit by an increase in loan and real estate loss reserves.[SEP]', 'e1': 'included', 'e2': 'terminated', 'labels': [1]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] Intel said it had corrected the problems and would start producing bugless chips next week.[SEP] \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip.[SEP] What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom.[SEP] \"These errata do not affect business programs,\" he said.[SEP]', 'e1': 'said', 'e2': 'emerge', 'labels': [2]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] NEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women.[SEP] The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes.[SEP] State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases.[SEP]', 'e1': 'needed', 'e2': 'identified', 'labels': [3]}],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplars_1_shot_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd97b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplar_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_0[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "    examplar_0.append(prompt)\n",
    "examplar_0 = \"\\n\\n\".join(examplar_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96917200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4955fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the context:\\nJim Unruh, Unisys\\'s president, said he is approaching next year with caution. He said the strength of the world-wide economy is suspect, and doesn\\'t see much revenue growth in the cards. He also said that the price wars flaring up in parts of the computer industry will continue through next year. He said the move toward standard operating systems means customers aren\\'t locked into buying from their traditional computer supplier and can force prices down.\\n\\nQ: What\\'s the temporal relation between the event \"suspect\" and \"flaring\"? \\nChoice A: suspect happens before flaring. \\nChoice B: suspect happens after flaring. \\nChoice C: suspect happens during flaring. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice A\\n\\nGiven the context:\\nThe latest results include some unusual write-downs, which had an after-tax impact of $4.9 million. Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989. In addition, operating results were hit by an increase in loan and real estate loss reserves.\\n\\nQ: What\\'s the temporal relation between the event \"included\" and \"terminated\"? \\nChoice A: included happens before terminated. \\nChoice B: included happens after terminated. \\nChoice C: included happens during terminated. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice B\\n\\nGiven the context:\\nIntel said it had corrected the problems and would start producing bugless chips next week. \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip. What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom. \"These errata do not affect business programs,\" he said.\\n\\nQ: What\\'s the temporal relation between the event \"said\" and \"emerge\"? \\nChoice A: said happens before emerge. \\nChoice B: said happens after emerge. \\nChoice C: said happens during emerge. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice C\\n\\nGiven the context:\\nNEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women. The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes. State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases.\\n\\nQ: What\\'s the temporal relation between the event \"needed\" and \"identified\"? \\nChoice A: needed happens before identified. \\nChoice B: needed happens after identified. \\nChoice C: needed happens during identified. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice D'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplar_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32c43416",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/prompt_1_icl_examplar_1_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f46b3338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0979e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplar_0 = \"\".join(open(\"prompts/prompt_1_icl_examplar_1_shot_0.txt\").readlines())\n",
    "oneshot_results_0 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n",
    "    \n",
    "examplar_1 = \"\".join(open(\"prompts/prompt_1_icl_examplar_1_shot_1.txt\").readlines())\n",
    "oneshot_results_1 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n",
    "\n",
    "examplar_2 = \"\".join(open(\"prompts/prompt_1_icl_examplar_1_shot_2.txt\").readlines())\n",
    "oneshot_results_2 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([item['choices'][0]['text'].strip() for item in oneshot_results_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb2169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "oneshot_preds_0 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_0]\n",
    "print(f1_score(labels, oneshot_preds_0, average='macro'), f1_score(labels, oneshot_preds_0, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_1_oneshot_pred_0.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_0, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee51848d",
   "metadata": {},
   "source": [
    "### run-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb6292b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_1_shot_1 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_1[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "    examplar_1.append(prompt)\n",
    "examplar_1 = \"\\n\\n\".join(examplar_1)\n",
    "    \n",
    "with open(\"prompts/prompt_1_icl_examplar_1_shot_1.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09e306",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_results_1 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "oneshot_preds_1 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_1]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_1, average='macro'), f1_score(labels, oneshot_preds_1, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be87549",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_1_oneshot_pred_1.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_1, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7f87e",
   "metadata": {},
   "source": [
    "## run-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7fdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_1_shot_2 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_2[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "    examplar_2.append(prompt)\n",
    "examplar_2 = \"\\n\\n\".join(examplar_2)\n",
    "    \n",
    "with open(\"prompts/prompt_1_icl_examplar_1_shot_2.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ee5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_results_2 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ebee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "oneshot_preds_2 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_2]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_2, average='macro'), f1_score(labels, oneshot_preds_2, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6435aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_1_oneshot_pred_2.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_2, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe04747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5731a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37bcb94f",
   "metadata": {},
   "source": [
    "# 3-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345e5ae2",
   "metadata": {},
   "source": [
    "### run-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84c266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(0)\n",
    "examplars_3_shot_0 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_0[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "        examplar_3_0.append(prompt)\n",
    "    \n",
    "examplar_3_0 = \"\\n\\n\".join(examplar_3_0)\n",
    "\n",
    "with open(\"prompts/prompt_1_icl_examplar_3_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37956785",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplar_3_0 = \"\".join(open(\"prompts/prompt_1_icl_examplar_3_shot_0.txt\").readlines())\n",
    "threeshot_results_0 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "examplar_3_1 = \"\".join(open(\"prompts/prompt_1_icl_examplar_3_shot_1.txt\").readlines())\n",
    "threeshot_results_1 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n",
    "\n",
    "    \n",
    "examplar_3_2 = \"\".join(open(\"prompts/prompt_1_icl_examplar_3_shot_2.txt\").readlines())    \n",
    "threeshot_results_2 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_0]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds, average='macro'), f1_score(labels_selected, threeshot_preds, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_1_threeshot_subsets_pred_0.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(l):\n",
    "    return sorted(Counter(l).items(), key = lambda x:x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0585b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05eaac",
   "metadata": {},
   "source": [
    "### run -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c71079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_3_shot_1 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_1[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "        examplar_3_1.append(prompt)\n",
    "    \n",
    "examplar_3_1 = \"\\n\\n\".join(examplar_3_1)\n",
    "\n",
    "with open(\"prompts/prompt_1_icl_examplar_3_shot_1.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a078b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_1 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice \"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a99afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds_1 =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_1]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds_1, average='macro'), f1_score(labels_selected, threeshot_preds_1, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_1_threeshot_subsets_pred_1.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds_1, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c9afd",
   "metadata": {},
   "source": [
    "## run-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a683a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_3_shot_2 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_2[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = \"Given the context:\\n\" + context + f\"\\n\\nQ: What's the temporal relation between the event \\\"{e1}\\\" and \\\"{e2}\\\"? \\nChoice A: {e1} happens before {e2}. \\nChoice B: {e1} happens after {e2}. \\nChoice C: {e1} happens during {e2}. \\nChoice D: unknown. \\nAnswer only with A, B, C, or D. \\n\\nA: Choice {convert_dict_rev[label]}\"\n",
    "        examplar_3_2.append(prompt)\n",
    "    \n",
    "examplar_3_2 = \"\\n\\n\".join(examplar_3_2)\n",
    "\n",
    "with open(\"prompts/prompt_1_icl_examplar_3_shot_2.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ae50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_2 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds_2 =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_2]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds_2, average='macro'), f1_score(labels_selected, threeshot_preds_2, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_1_threeshot_subsets_pred_2.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds_2, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77e96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8523ded9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
