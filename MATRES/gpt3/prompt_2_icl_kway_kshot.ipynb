{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43428f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "features_valid = json.load(open(\"../data/valid_subset_text.json\"))\n",
    "features_valid_erp = json.load(open(\"../dataset_bias/valid_subset_text_erp.json\"))\n",
    "features_valid_tense_all = json.load(open(\"../dataset_bias/valid_subset_text_tense_bias_vague.json\"))\n",
    "\n",
    "# features_valid_tense_vague = [item for item in features_valid_tense_all if item['labels'][0] == 3]\n",
    "# features_valid_dep = json.load(open(\"../dataset_bias/valid_text_features_matres_dep_bias.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe89afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dad34001",
   "metadata": {},
   "source": [
    "# ICL, m way, k-shot\n",
    "\n",
    "\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9cae814",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_dict = {'BEFORE':0, 'AFTER':1, 'EQUAL':2, 'VAGUE':3}\n",
    "convert_dict_rev = {0:'before', 1:'after', 2:'equal', 3:'vague'}\n",
    "def parse_result(ans):\n",
    "    return convert_dict.get(ans.upper(), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d12f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = json.load(open(\"../data/train_text_features_matres.json\"))\n",
    "train_by_labels = [[item for item in train if item['labels'][0] == i] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f98397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4316c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(0)\n",
    "examplars_1_shot_0 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f77914d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([{'text': \"[CLS] Jim Unruh, Unisys's president, said he is approaching next year with caution.[SEP] He said the strength of the world-wide economy is suspect, and doesn't see much revenue growth in the cards.[SEP] He also said that the price wars flaring up in parts of the computer industry will continue through next year.[SEP] He said the move toward standard operating systems means customers aren't locked into buying from their traditional computer supplier and can force prices down.[SEP]\", 'e1': 'suspect', 'e2': 'flaring', 'labels': [0]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] The latest results include some unusual write-downs, which had an after-tax impact of $4.9 million.[SEP] Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989.[SEP] In addition, operating results were hit by an increase in loan and real estate loss reserves.[SEP]', 'e1': 'included', 'e2': 'terminated', 'labels': [1]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] Intel said it had corrected the problems and would start producing bugless chips next week.[SEP] \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip.[SEP] What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom.[SEP] \"These errata do not affect business programs,\" he said.[SEP]', 'e1': 'said', 'e2': 'emerge', 'labels': [2]}],\n",
       "       dtype=object),\n",
       " array([{'text': '[CLS] NEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women.[SEP] The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes.[SEP] State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases.[SEP]', 'e1': 'needed', 'e2': 'identified', 'labels': [3]}],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplars_1_shot_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd97b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "examplar_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_0[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "    examplar_0.append(prompt)\n",
    "examplar_0 = \"\\n\\n\".join(examplar_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96917200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4955fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine the temporal order from \"suspect\" to \"flaring\" in the following sentence: \"Jim Unruh, Unisys\\'s president, said he is approaching next year with caution. He said the strength of the world-wide economy is suspect, and doesn\\'t see much revenue growth in the cards. He also said that the price wars flaring up in parts of the computer industry will continue through next year. He said the move toward standard operating systems means customers aren\\'t locked into buying from their traditional computer supplier and can force prices down.\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: before\\n\\nDetermine the temporal order from \"included\" to \"terminated\" in the following sentence: \"The latest results include some unusual write-downs, which had an after-tax impact of $4.9 million. Those included costs associated with the potential Valley Federal Savings and Loan Association acquisition, which was terminated on Sept. 27, 1989. In addition, operating results were hit by an increase in loan and real estate loss reserves.\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: after\\n\\nDetermine the temporal order from \"said\" to \"emerge\" in the following sentence: \"Intel said it had corrected the problems and would start producing bugless chips next week. \"We should not be seeing any more,\" said Bill Rash, Intel\\'s director for the486 chip. What\\'s more, the bugs only emerge on esoteric applications such as computer-aided design and scientific calculations, he said, and then very seldom. \"These errata do not affect business programs,\" he said.\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: equal\\n\\nDetermine the temporal order from \"needed\" to \"identified\" in the following sentence: \"NEWARK, N.J. _ A new Essex County task force began delving Thursday into the slayings of 14 black women over the last five years in the Newark area, as law-enforcement officials acknowledged that they needed to work harder to solve the cases of murdered women. The police and prosecutors said they had identified different suspects in six of the cases and had yet to find any pattern linking the killings or the victims, several of whom were believed to be prostitutes. State, county and local law-enforcement officials have expressed concerns in recent months about a possible pattern of murdered women and a disproportionate number of unsolved cases.\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: vague'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examplar_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c43416",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompts/prompt_2_icl_examplar_1_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b123f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [47:45<00:00,  2.87s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_0 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5143b010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'before': 857,\n",
       "         'after': 128,\n",
       "         'equal': 7,\n",
       "         'seeking': 1,\n",
       "         'keeping': 1,\n",
       "         'representing': 1,\n",
       "         'been': 2,\n",
       "         'followed': 2,\n",
       "         'are': 1})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter([item['choices'][0]['text'].strip() for item in oneshot_results_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38eb2169",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_preds_0 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94b83ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21993212254632177 0.499\n"
     ]
    }
   ],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_0, average='macro'), f1_score(labels, oneshot_preds_0, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06bb0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_2_oneshot_pred_0.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_0, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5d703",
   "metadata": {},
   "source": [
    "### run-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4ea680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_1_shot_1 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_1[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "    examplar_1.append(prompt)\n",
    "examplar_1 = \"\\n\\n\".join(examplar_1)\n",
    "    \n",
    "with open(\"prompts/prompt_2_icl_examplar_1_shot_1.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f3e1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [48:08<00:00,  2.89s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_1 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82a57888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22143296136408955 0.493\n"
     ]
    }
   ],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "oneshot_preds_1 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_1]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_1, average='macro'), f1_score(labels, oneshot_preds_1, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3832c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_2_oneshot_pred_1.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_1, writer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e8f5f3",
   "metadata": {},
   "source": [
    "## run-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2294ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_1_shot_2 = [np.random.choice(train_by_labels[i], 1) for i in range(4)]\n",
    "\n",
    "examplar_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    item = examplars_1_shot_2[i][0]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    label = item['labels'][0]\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "    examplar_2.append(prompt)\n",
    "examplar_2 = \"\\n\\n\".join(examplar_2)\n",
    "    \n",
    "with open(\"prompts/prompt_2_icl_examplar_1_shot_2.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86dacd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [49:58<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "oneshot_results_2 = []\n",
    "for i in tqdm(range(len(features_valid))):\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            oneshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fdb2d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19800593031875463 0.501\n"
     ]
    }
   ],
   "source": [
    "labels = [features_valid[i]['labels'][0] for i in range(len(features_valid))]\n",
    "oneshot_preds_2 = [parse_result(item['choices'][0]['text'].strip()) for item in oneshot_results_2]\n",
    "\n",
    "print(f1_score(labels, oneshot_preds_2, average='macro'), f1_score(labels, oneshot_preds_2, average=\"micro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c434ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/template_2_oneshot_pred_2.json\", \"w\") as writer:\n",
    "    json.dump(oneshot_preds_2, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b02a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0e32a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37bcb94f",
   "metadata": {},
   "source": [
    "# 3-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160ea06",
   "metadata": {},
   "source": [
    "### run-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b84c266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(0)\n",
    "examplars_3_shot_0 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_0 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_0[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "        examplar_3_0.append(prompt)\n",
    "    \n",
    "examplar_3_0 = \"\\n\\n\".join(examplar_3_0)\n",
    "\n",
    "with open(\"prompts/prompt_2_icl_examplar_3_shot_0.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37956785",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_0 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_0.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_0 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_0]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds, average='macro'), f1_score(labels_selected, threeshot_preds, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_2_threeshot_subsets_pred_0.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa4532",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(l):\n",
    "    return sorted(Counter(l).items(), key = lambda x:x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe0e184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf6df1",
   "metadata": {},
   "source": [
    "### run -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ac477d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(1)\n",
    "examplars_3_shot_1 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_1 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_1[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "        examplar_3_1.append(prompt)\n",
    "    \n",
    "examplar_3_1 = \"\\n\\n\".join(examplar_3_1)\n",
    "\n",
    "with open(\"prompts/prompt_2_icl_examplar_3_shot_1.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72243509",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_1 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_1.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_1 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d5ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds_1 =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_1]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds_1, average='macro'), f1_score(labels_selected, threeshot_preds_1, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_2_threeshot_subsets_pred_1.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds_1, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321cb528",
   "metadata": {},
   "source": [
    "## run-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c0f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-shot\n",
    "np.random.seed(2)\n",
    "examplars_3_shot_2 = [np.random.choice(train_by_labels[i], 3) for i in range(4)]\n",
    "\n",
    "examplar_3_2 = []\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(3):\n",
    "        item = examplars_3_shot_2[i][j]\n",
    "        context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "        label = item['labels'][0]\n",
    "        e1 = item['e1']\n",
    "        e2 = item['e2']\n",
    "        prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer: {convert_dict_rev[label]}\"\n",
    "        examplar_3_2.append(prompt)\n",
    "    \n",
    "examplar_3_2 = \"\\n\\n\".join(examplar_3_2)\n",
    "\n",
    "with open(\"prompts/prompt_2_icl_examplar_3_shot_2.txt\", \"w\") as writer:\n",
    "    writer.writelines(examplar_3_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c5f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "threeshot_results_2 = []\n",
    "\n",
    "# selected_subsubset = np.random.permutation(len(features_valid))[:200]\n",
    "# np.save(\"subsubset_idx_200\", selected_subsubset)\n",
    "selected_subsubset = np.load(\"subsubset_idx_200.npy\", allow_pickle=True)\n",
    "\n",
    "for i in tqdm(selected_subsubset):\n",
    "\n",
    "    item = features_valid[i]\n",
    "    context = item['text'].replace(\"[CLS]\", \"\").replace(\"[SEP]\", \"\").strip()\n",
    "    e1 = item['e1']\n",
    "    e2 = item['e2']\n",
    "    \n",
    "    prompt = f\"Determine the temporal order from \\\"{e1}\\\" to \\\"{e2}\\\" in the following sentence: \\\"{context}\\\". Only answer one word from AFTER, BEFORE, EQUAL, VAGUE. Answer:\"\n",
    "#     print(prompt)\n",
    "    while True:\n",
    "        try:\n",
    "            threeshot_results_2.append(openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=examplar_3_2 + \"\\n\\n\" + prompt,\n",
    "                        max_tokens=20,\n",
    "                        temperature=0\n",
    "            ))\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(10)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370fc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_selected = [features_valid[i]['labels'][0] for i in selected_subsubset]\n",
    "threeshot_preds_2 =  [parse_result(item['choices'][0]['text'].strip()) for item in threeshot_results_2]\n",
    "\n",
    "print(f1_score(labels_selected, threeshot_preds_2, average='macro'), f1_score(labels_selected, threeshot_preds_2, average=\"micro\"))\n",
    "\n",
    "with open(\"results/template_2_threeshot_subsets_pred_2.json\", \"w\") as writer:\n",
    "    json.dump(threeshot_preds_2, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
